{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "487344de",
      "metadata": {
        "id": "487344de"
      },
      "source": [
        "# AutoGluon Tabular - In Depth\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/tabular-indepth.ipynb)\n",
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/tabular-indepth.ipynb)\n",
        "\n",
        "\n",
        "**Tip**: If you are new to AutoGluon, review [Predicting Columns in a Table - Quick Start](tabular-quick-start.ipynb) to learn the basics of the AutoGluon API. To learn how to add your own custom models to the set that AutoGluon trains, tunes, and ensembles, review [Adding a custom model to AutoGluon](advanced/tabular-custom-model.ipynb).\n",
        "\n",
        "This tutorial describes how you can exert greater control when using AutoGluon's `fit()` or `predict()`. Recall that to maximize predictive performance, you should first try `TabularPredictor()` and `fit()` with all default arguments.  Then, consider non-default arguments for `TabularPredictor(eval_metric=...)`, and `fit(presets=...)`.  Later, you can experiment with other arguments to fit() covered in this in-depth tutorial like `hyperparameter_tune_kwargs`, `hyperparameters`, `num_stack_levels`, `num_bag_folds`, `num_bag_sets`, etc.\n",
        "\n",
        "Using the same census data table as in the [Predicting Columns in a Table - Quick Start](tabular-quick-start.ipynb) tutorial, we'll now predict the `occupation` of an individual - a multiclass classification problem. Start by importing AutoGluon's TabularPredictor and TabularDataset, and loading the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
      "metadata": {
        "tags": [
          "remove-cell"
        ],
        "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
        "outputId": "1b72f229-5e88-46fa-8985-bd3bf58b2a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon.tabular[all]\n",
            "  Downloading autogluon.tabular-1.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (1.16.2)\n",
            "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (3.5)\n",
            "Collecting autogluon.core==1.4.0 (from autogluon.tabular[all])\n",
            "  Downloading autogluon.core-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.4.0 (from autogluon.tabular[all])\n",
            "  Downloading autogluon.features-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all])\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (2.8.4)\n",
            "Collecting loguru (from autogluon.tabular[all])\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting lightgbm<4.7,>=4.0 (from autogluon.tabular[all])\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting einx (from autogluon.tabular[all])\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting xgboost<3.1,>=2.0 (from autogluon.tabular[all])\n",
            "  Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (4.57.1)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (3.8.7)\n",
            "Collecting torch<2.8,>=2.2 (from autogluon.tabular[all])\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting omegaconf (from autogluon.tabular[all])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]) (0.35.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.tabular[all]) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.tabular[all]) (2.32.4)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.tabular[all]) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.4.0->autogluon.tabular[all])\n",
            "  Downloading boto3-1.40.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.4.0 (from autogluon.core==1.4.0->autogluon.tabular[all])\n",
            "  Downloading autogluon.common-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (21.0.0)\n",
            "Collecting ray<2.45,>=2.10.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting pyarrow>=15.0.0 (from autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.tabular[all]) (5.9.5)\n",
            "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.tabular[all]) (1.5.2)\n",
            "Collecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all])\n",
            "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (1.17.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (25.0)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (1.8.12)\n",
            "Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (0.0.2)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (0.23.0+cpu)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (6.0.3)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (11.3.0)\n",
            "Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (2.5.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular[all]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular[all]) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.tabular[all]) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (0.19.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (2.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.tabular[all]) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.tabular[all]) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.tabular[all]) (1.14.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.tabular[all]) (2025.9.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch<2.8,>=2.2->autogluon.tabular[all])\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting frozendict (from einx->autogluon.tabular[all])\n",
            "  Downloading frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]) (1.1.10)\n",
            "Requirement already satisfied: safetensors[torch] in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]) (0.6.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->autogluon.tabular[all])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->autogluon.tabular[all]) (2025.9.18)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->autogluon.tabular[all]) (0.22.1)\n",
            "Collecting botocore<1.41.0,>=1.40.55 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular[all])\n",
            "  Downloading botocore-1.40.55-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular[all])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular[all])\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular[all]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular[all]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular[all]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular[all]) (3.2.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9->autogluon.tabular[all]) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9->autogluon.tabular[all]) (0.4.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (8.3.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (1.1.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (6.32.1)\n",
            "Collecting aiosignal (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting aiohttp>=3.7 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading aiohttp-3.13.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading colorful-0.5.7-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.4.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (1.75.1)\n",
            "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (0.23.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (7.3.1)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading virtualenv-20.35.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular[all]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular[all]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular[all]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular[all]) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.8,>=2.2->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.11 (from fastai<2.9,>=2.3.1->autogluon.tabular[all])\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]) (14.2.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]) (0.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy<3.9->autogluon.tabular[all]) (3.0.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]) (9.1.2)\n",
            "Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.12/dist-packages (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]) (0.22.2)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (25.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (6.7.0)\n",
            "Collecting propcache>=0.2.0 (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (1.17.3)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (4.5.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (0.27.1)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (2.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (2.38.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]) (0.1.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0; extra == \"all\"->autogluon.tabular[all]) (0.6.1)\n",
            "Downloading autogluon.core-1.4.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.4.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.4.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m732.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m761.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.40.55-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozendict-2.4.6-py312-none-any.whl (16 kB)\n",
            "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.13.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading botocore-1.40.55-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.35.3-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.7-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=145c64a137ff4fc08f051d49de17e5a28a4c83bb770d901a3eccf32347b058c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: py4j, py-spy, opencensus-context, nvidia-cusparselt-cu12, distlib, colorful, antlr4-python3-runtime, virtualenv, triton, tensorboardX, pyarrow, propcache, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, jmespath, graphviz, future, frozenlist, frozendict, aiohappyeyeballs, yarl, xgboost, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, lightgbm, hyperopt, einx, botocore, aiosignal, s3transfer, nvidia-cusolver-cu12, catboost, aiohttp, torch, ray, opencensus, boto3, aiohttp_cors, torchvision, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 21.0.0\n",
            "    Uninstalling pyarrow-21.0.0:\n",
            "      Successfully uninstalled pyarrow-21.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cpu\n",
            "    Uninstalling torch-2.8.0+cpu:\n",
            "      Successfully uninstalled torch-2.8.0+cpu\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cpu\n",
            "    Uninstalling torchvision-0.23.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.23.0+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cpu requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiohttp_cors-0.8.1 aiosignal-1.4.0 antlr4-python3-runtime-4.9.3 autogluon.common-1.4.0 autogluon.core-1.4.0 autogluon.features-1.4.0 autogluon.tabular-1.4.0 boto3-1.40.55 botocore-1.40.55 catboost-1.2.8 colorful-0.5.7 distlib-0.4.0 einx-0.3.0 frozendict-2.4.6 frozenlist-1.8.0 future-1.0.0 graphviz-0.21 hyperopt-0.2.7 jmespath-1.0.1 lightgbm-4.6.0 loguru-0.7.3 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 omegaconf-2.3.0 opencensus-0.11.4 opencensus-context-0.1.3 propcache-0.4.1 py-spy-0.4.1 py4j-0.10.9.9 pyarrow-20.0.0 ray-2.44.1 s3transfer-0.14.0 tensorboardX-2.6.4 torch-2.7.1 torchvision-0.22.1 triton-3.3.1 virtualenv-20.35.3 xgboost-3.0.5 yarl-1.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "8a0585f6b2a84044ae10245d88d8e79f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install autogluon.tabular[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fae7a5f3",
      "metadata": {
        "id": "fae7a5f3",
        "outputId": "59ce74aa-7302-425c-a7b2-97c63a13cffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       age workclass  fnlwgt      education  education-num  \\\n",
            "6118    51   Private   39264   Some-college             10   \n",
            "23204   58   Private   51662           10th              6   \n",
            "29590   40   Private  326310   Some-college             10   \n",
            "18116   37   Private  222450        HS-grad              9   \n",
            "33964   62   Private  109190      Bachelors             13   \n",
            "\n",
            "            marital-status        occupation    relationship    race      sex  \\\n",
            "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
            "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
            "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
            "18116        Never-married             Sales   Not-in-family   White     Male   \n",
            "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
            "\n",
            "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
            "6118              0             0              40   United-States    >50K  \n",
            "23204             0             0               8   United-States   <=50K  \n",
            "29590             0             0              44   United-States   <=50K  \n",
            "18116             0          2339              40     El-Salvador   <=50K  \n",
            "33964         15024             0              40   United-States    >50K  \n",
            "Summary of occupation column: \n",
            " count              1000\n",
            "unique               15\n",
            "top        Craft-repair\n",
            "freq                142\n",
            "Name: occupation, dtype: object\n"
          ]
        }
      ],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
        "subsample_size = 1000  # subsample subset of data for faster demo, try setting this to much larger values\n",
        "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
        "print(train_data.head())\n",
        "\n",
        "label = 'occupation'\n",
        "print(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n",
        "\n",
        "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
        "y_test = test_data[label]\n",
        "test_data_nolabel = test_data.drop(columns=[label])  # delete label column\n",
        "\n",
        "metric = 'accuracy' # we specify eval-metric just for demo (unnecessary as it's the default)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specifying hyperparameters and tuning them\n",
        "\n",
        "**Note: We don't recommend doing hyperparameter-tuning with AutoGluon in most cases**. AutoGluon achieves its best performance without hyperparameter tuning and simply specifying `presets=\"best_quality\"`.\n",
        "\n",
        "We first demonstrate hyperparameter-tuning and how you can provide your own validation dataset that AutoGluon internally relies on to: tune hyperparameters, early-stop iterative training, and construct model ensembles. One reason you may specify validation data is when future test data will stem from a different distribution than training data (and your specified validation data is more representative of the future data that will likely be encountered).\n",
        "\n",
        " If you don't have a strong reason to provide your own validation dataset, we recommend you omit the `tuning_data` argument. This lets AutoGluon automatically select validation data from your provided training set (it uses smart strategies such as stratified sampling).  For greater control, you can specify the `holdout_frac` argument to tell AutoGluon what fraction of the provided training data to hold out for validation.\n",
        "\n",
        "**Caution:** Since AutoGluon tunes internal knobs based on this validation data, performance estimates reported on this data may be over-optimistic. For unbiased performance estimates, you should always call `predict()` on a separate dataset (that was never passed to `fit()`), as we did in the previous **Quick-Start** tutorial. We also emphasize that most options specified in this tutorial are chosen to minimize runtime for the purposes of demonstration and you should select more reasonable values in order to obtain high-quality models.\n",
        "\n",
        "`fit()` trains neural networks and various types of tree ensembles by default. You can specify various hyperparameter values for each type of model. For each hyperparameter, you can either specify a single fixed value, or a search space of values to consider during hyperparameter optimization. Hyperparameters which you do not specify are left at default settings chosen automatically by AutoGluon, which may be fixed values or search spaces.\n",
        "\n",
        "Refer to the [Search Space documentation](../../api/autogluon.common.space.rst) to learn more about AutoGluon search space."
      ],
      "metadata": {
        "collapsed": false,
        "id": "98733672"
      },
      "id": "98733672"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251018_191844\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          4\n",
            "Memory Avail:       44.74 GB / 47.05 GB (95.1%)\n",
            "Disk Space Avail:   196.87 GB / 225.33 GB (87.4%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Beginning AutoGluon training ... Time limit = 120s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251018_191844\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       occupation\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 13 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
            "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.996\n",
            "Train Data Class Count: 13\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    46081.04 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.07s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 796, Val Rows: 200\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': [{'num_boost_round': 100, 'num_leaves': Int: lower=26, upper=66}],\n",
            "\t'NN_TORCH': [{'num_epochs': 10, 'learning_rate': Real: lower=0.0001, upper=0.01, 'activation': Categorical['relu', 'softrelu', 'tanh'], 'dropout_prob': Real: lower=0.0, upper=0.5}],\n",
            "}\n",
            "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
            "Hyperparameter tuning model: LightGBM ... Tuning model for up to 53.97s of the 119.93s of remaining time.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bc2430645de4adb8655d48987b6284f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitted model: LightGBM/T1 ...\n",
            "\t0.37\t = Validation score   (accuracy)\n",
            "\t0.99s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T2 ...\n",
            "\t0.355\t = Validation score   (accuracy)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T3 ...\n",
            "\t0.375\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T4 ...\n",
            "\t0.36\t = Validation score   (accuracy)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitted model: LightGBM/T5 ...\n",
            "\t0.375\t = Validation score   (accuracy)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 53.97s of the 103.12s of remaining time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch   |\n",
            "+---------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator  |\n",
            "| Scheduler                        FIFOScheduler    |\n",
            "| Number of trials                 5                |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251018_191844/models/NeuralNetTorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitted model: NeuralNetTorch/1f22e786 ...\n",
            "\t0.36\t = Validation score   (accuracy)\n",
            "\t5.16s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitted model: NeuralNetTorch/de2aa886 ...\n",
            "\t0.32\t = Validation score   (accuracy)\n",
            "\t3.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitted model: NeuralNetTorch/5bc123e2 ...\n",
            "\t0.325\t = Validation score   (accuracy)\n",
            "\t2.53s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitted model: NeuralNetTorch/b40ee483 ...\n",
            "\t0.325\t = Validation score   (accuracy)\n",
            "\t3.29s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitted model: NeuralNetTorch/1fe7bba6 ...\n",
            "\t0.345\t = Validation score   (accuracy)\n",
            "\t2.45s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.93s of the 72.21s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM/T3': 1.0}\n",
            "\t0.375\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 47.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 51794.3 rows/s (200 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251018_191844\")\n"
          ]
        }
      ],
      "source": [
        "from autogluon.common import space\n",
        "\n",
        "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
        "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
        "    'learning_rate': space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
        "    'activation': space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
        "    'dropout_prob': space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
        "}\n",
        "\n",
        "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
        "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
        "    'num_leaves': space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
        "}\n",
        "\n",
        "hyperparameters = {  # hyperparameters of each model type\n",
        "                   'GBM': gbm_options,\n",
        "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
        "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
        "\n",
        "time_limit = 2*60  # train various models for ~2 min\n",
        "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
        "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
        "\n",
        "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
        "    'num_trials': num_trials,\n",
        "    'scheduler' : 'local',\n",
        "    'searcher': search_strategy,\n",
        "}  # Refer to TabularPredictor.fit docstring for all valid values\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
        "    train_data,\n",
        "    time_limit=time_limit,\n",
        "    hyperparameters=hyperparameters,\n",
        "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
        ")"
      ],
      "metadata": {
        "id": "87f28cf4",
        "outputId": "ca224e6d-0d93-4c23-e299-e44983b7974a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4bc2430645de4adb8655d48987b6284f",
            "344166432375424aadf062667c1d8a0b",
            "817e6d6d62814965ba9b831fbc4ca5f2",
            "dc2a107fea8149c7860ce477104721ed",
            "b5c96e7c556d491c86bec0d846d5b36a",
            "e631b6c08efa41f1817dd6522349e151",
            "496e6fd96f4e4a4dbb6cee425a245c8e",
            "541564df09a349feb13b40905b202a08",
            "baf74ab673ff4fd9a3b557340640d7e3",
            "16c07432e8034d9496fb00ecd9a4c597",
            "cccb5184107c4244a6b0b0a3edb929ba"
          ]
        }
      },
      "id": "87f28cf4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We again demonstrate how to use the trained models to predict on the test data."
      ],
      "metadata": {
        "collapsed": false,
        "id": "816e4beb"
      },
      "id": "816e4beb"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:   [' Other-service', ' Craft-repair', ' Exec-managerial', ' Sales', ' Other-service']\n"
          ]
        }
      ],
      "source": [
        "y_pred = predictor.predict(test_data_nolabel)\n",
        "print(\"Predictions:  \", list(y_pred)[:5])\n",
        "perf = predictor.evaluate(test_data, auxiliary_metrics=False)"
      ],
      "metadata": {
        "id": "3bf2965a",
        "outputId": "16df990d-6144-457c-a7ca-2be134acea55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3bf2965a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following to view a summary of what happened during `fit()`. Now this command will show details of the hyperparameter-tuning process for each type of model:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5c2f4648"
      },
      "id": "5c2f4648"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                      model  score_val eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0               LightGBM/T3      0.375    accuracy       0.003239  0.396597                0.003239           0.396597            1       True          3\n",
            "1       WeightedEnsemble_L2      0.375    accuracy       0.003861  0.417597                0.000622           0.020999            2       True         11\n",
            "2               LightGBM/T5      0.375    accuracy       0.017459  0.727413                0.017459           0.727413            1       True          5\n",
            "3               LightGBM/T1      0.370    accuracy       0.003160  0.992579                0.003160           0.992579            1       True          1\n",
            "4               LightGBM/T4      0.360    accuracy       0.006466  0.662577                0.006466           0.662577            1       True          4\n",
            "5   NeuralNetTorch/1f22e786      0.360    accuracy       0.009550  5.163287                0.009550           5.163287            1       True          6\n",
            "6               LightGBM/T2      0.355    accuracy       0.004400  0.733110                0.004400           0.733110            1       True          2\n",
            "7   NeuralNetTorch/1fe7bba6      0.345    accuracy       0.008660  2.445330                0.008660           2.445330            1       True         10\n",
            "8   NeuralNetTorch/5bc123e2      0.325    accuracy       0.008669  2.527924                0.008669           2.527924            1       True          8\n",
            "9   NeuralNetTorch/b40ee483      0.325    accuracy       0.010939  3.292371                0.010939           3.292371            1       True          9\n",
            "10  NeuralNetTorch/de2aa886      0.320    accuracy       0.012303  3.029431                0.012303           3.029431            1       True          7\n",
            "Number of models trained: 11\n",
            "Types of models trained:\n",
            "{'WeightedEnsembleModel', 'TabularNeuralNetTorchModel', 'LGBModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
            "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "('int', ['bool']) : 2 | ['sex', 'class']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/autogluon/core/utils/plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        }
      ],
      "source": [
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "id": "1bfc4fe3",
        "outputId": "82d08ee1-385e-4c9e-c4c6-261e461459e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1bfc4fe3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above example, the predictive performance may be poor because we specified very little training to ensure quick runtimes.  You can call `fit()` multiple times while modifying the above settings to better understand how these choices affect performance outcomes. For example: you can increase `subsample_size` to train using a larger dataset, increase the `num_epochs` and `num_boost_round` hyperparameters, and increase the `time_limit` (which you should do for all code in these tutorials).  To see more detailed output during the execution of `fit()`, you can also pass in the argument: `verbosity=3`."
      ],
      "metadata": {
        "collapsed": false,
        "id": "1d06b7ab"
      },
      "id": "1d06b7ab"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model ensembling with stacking/bagging\n",
        "\n",
        "Beyond hyperparameter-tuning with a correctly-specified evaluation metric, two other methods to boost predictive performance are [bagging and stack-ensembling](https://arxiv.org/abs/2003.06505).  You'll often see performance improve if you specify `num_bag_folds` = 5-10, `num_stack_levels` = 1 in the call to `fit()`, but this will increase training times and memory/disk usage."
      ],
      "metadata": {
        "collapsed": false,
        "id": "cc894bfde6cbc5f1"
      },
      "id": "cc894bfde6cbc5f1"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d821c4af",
      "metadata": {
        "id": "d821c4af",
        "outputId": "f24302ec-168f-4e83-863d-7dd428b9c4aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251018_191932\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          4\n",
            "Memory Avail:       43.87 GB / 47.05 GB (93.2%)\n",
            "Disk Space Avail:   196.83 GB / 225.33 GB (87.4%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251018_191932\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    44923.78 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.50 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.07s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{'num_epochs': 2}],\n",
            "\t'GBM': [{'num_boost_round': 20}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t0.823\t = Validation score   (accuracy)\n",
            "\t4.14s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t0.744\t = Validation score   (accuracy)\n",
            "\t6.4s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.823\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 2 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L2 ...\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t0.829\t = Validation score   (accuracy)\n",
            "\t3.94s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t0.744\t = Validation score   (accuracy)\n",
            "\t6.42s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L2': 1.0}\n",
            "\t0.829\t = Validation score   (accuracy)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 30.74s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2896.0 rows/s (200 batch size)\n",
            "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (1000 rows).\n",
            "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251018_191932\")\n"
          ]
        }
      ],
      "source": [
        "label = 'class'  # Now lets predict the \"class\" column (binary classification)\n",
        "test_data_nolabel = test_data.drop(columns=[label])\n",
        "y_test = test_data[label]\n",
        "save_path = 'agModels-predictClass'  # folder where to store trained models\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data,\n",
        "    num_bag_folds=5, num_bag_sets=1, num_stack_levels=1,\n",
        "    hyperparameters = {'NN_TORCH': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}},  # last  argument is just for quick demo here, omit it in real applications\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f61e8d",
      "metadata": {
        "id": "38f61e8d"
      },
      "source": [
        "You should not provide `tuning_data` when stacking/bagging, and instead provide all your available data as `train_data` (which AutoGluon will split in more intellgent ways). `num_bag_sets` controls how many times the k-fold bagging process is repeated to further reduce variance (increasing this may further boost accuracy but will substantially increase training times, inference latency, and memory/disk usage). Rather than manually searching for good bagging/stacking values yourself, AutoGluon will automatically select good values for you if you specify `auto_stack` instead (which is used in the `best_quality` preset):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e1cf666c",
      "metadata": {
        "id": "e1cf666c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e546c47d-9624-4af4-c8c1-8fc07d4c7124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          4\n",
            "Memory Avail:       43.46 GB / 47.05 GB (92.4%)\n",
            "Disk Space Avail:   196.83 GB / 225.33 GB (87.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
            "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/agModels-predictClass\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    44500.19 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.50 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.06s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'FASTAI': [{'num_epochs': 10}],\n",
            "\t'GBM': [{'num_boost_round': 200}],\n",
            "}\n",
            "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t0.7764\t = Validation score   (balanced_accuracy)\n",
            "\t9.28s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t0.7251\t = Validation score   (balanced_accuracy)\n",
            "\t13.62s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.7764\t = Validation score   (balanced_accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 26.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1948.3 rows/s (125 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/agModels-predictClass\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    model  score_test  score_val        eval_metric  \\\n",
              "0         LightGBM_BAG_L1    0.743784   0.776399  balanced_accuracy   \n",
              "1     WeightedEnsemble_L2    0.743784   0.776399  balanced_accuracy   \n",
              "2  NeuralNetFastAI_BAG_L1    0.728689   0.725071  balanced_accuracy   \n",
              "\n",
              "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
              "0        0.276115       0.064090   9.282016                 0.276115   \n",
              "1        0.277327       0.064651   9.300483                 0.001212   \n",
              "2        2.711638       0.054682  13.619211                 2.711638   \n",
              "\n",
              "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                0.064090           9.282016            1       True   \n",
              "1                0.000561           0.018467            2       True   \n",
              "2                0.054682          13.619211            1       True   \n",
              "\n",
              "   fit_order  \n",
              "0          1  \n",
              "1          3  \n",
              "2          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc7240d7-2111-46a6-9aaf-8a38a1942d3d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.276115</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>0.276115</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.277327</td>\n",
              "      <td>0.064651</td>\n",
              "      <td>9.300483</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.728689</td>\n",
              "      <td>0.725071</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>2.711638</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>2.711638</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc7240d7-2111-46a6-9aaf-8a38a1942d3d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc7240d7-2111-46a6-9aaf-8a38a1942d3d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc7240d7-2111-46a6-9aaf-8a38a1942d3d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3f98a86f-af18-4db1-a4af-7c4fbed6db65\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f98a86f-af18-4db1-a4af-7c4fbed6db65')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3f98a86f-af18-4db1-a4af-7c4fbed6db65 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"LightGBM_BAG_L1\",\n          \"WeightedEnsemble_L2\",\n          \"NeuralNetFastAI_BAG_L1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008714883202075007,\n        \"min\": 0.7286894741358236,\n        \"max\": 0.7437840946238461,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7286894741358236,\n          0.7437840946238461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029633821780482274,\n        \"min\": 0.7250714045698925,\n        \"max\": 0.776398689516129,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7250714045698925,\n          0.776398689516129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"balanced_accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4057998940971064,\n        \"min\": 0.27611494064331055,\n        \"max\": 2.7116377353668213,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.27611494064331055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005600696606507432,\n        \"min\": 0.054682016372680664,\n        \"max\": 0.0646512508392334,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06408977508544922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.498766971148709,\n        \"min\": 9.282016038894653,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.282016038894653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.491852787476108,\n        \"min\": 0.0012123584747314453,\n        \"max\": 2.7116377353668213,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.27611494064331055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034286497966529356,\n        \"min\": 0.0005614757537841797,\n        \"max\": 0.06408977508544922,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06408977508544922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.947479861523583,\n        \"min\": 0.018466711044311523,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.282016038894653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Lets also specify the \"balanced_accuracy\" metric\n",
        "predictor = TabularPredictor(label=label, eval_metric='balanced_accuracy', path=save_path).fit(\n",
        "    train_data, auto_stack=True,\n",
        "    calibrate_decision_threshold=False,  # Disabling for demonstration in next section\n",
        "    hyperparameters={'FASTAI': {'num_epochs': 10}, 'GBM': {'num_boost_round': 200}}  # last 2 arguments are for quick demo, omit them in real applications\n",
        ")\n",
        "predictor.leaderboard(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Often stacking/bagging will produce superior accuracy than hyperparameter-tuning, but you may try combining both techniques (note: specifying `presets='best_quality'` in `fit()` simply sets `auto_stack=True`).\n",
        "\n",
        "## Decision Threshold Calibration\n",
        "\n",
        "Major metric score improvements can be achieved in binary classification for metrics such as `\"f1\"` and `\"balanced_accuracy\"` by adjusting the prediction decision threshold via `calibrate_decision_threshold` to a value other than the default 0.5.\n",
        "\n",
        "Below is an example of the `\"balanced_accuracy\"` score achieved on the test data with and without calibrating the decision threshold:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "209aed94e755e675"
      },
      "id": "209aed94e755e675"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior to calibration (predictor.decision_threshold=0.5):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calibrating decision threshold to optimize metric balanced_accuracy | Checking 51 thresholds...\n",
            "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
            "\tBase Threshold: 0.500\t| val: 0.7764\n",
            "\tBest Threshold: 0.250\t| val: 0.7926\n",
            "Updating predictor.decision_threshold from 0.5 -> 0.25\n",
            "\tThis will impact how prediction probabilities are converted to predictions in binary classification.\n",
            "\tPrediction probabilities of the positive class >0.25 will be predicted as the positive class ( >50K). This can significantly impact metric scores.\n",
            "\tYou can update this value via `predictor.set_decision_threshold`.\n",
            "\tYou can calculate an optimal decision threshold on the validation data via `predictor.calibrate_decision_threshold()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After calibration (predictor.decision_threshold=0.25):\n"
          ]
        }
      ],
      "source": [
        "print(f'Prior to calibration (predictor.decision_threshold={predictor.decision_threshold}):')\n",
        "scores = predictor.evaluate(test_data)\n",
        "\n",
        "calibrated_decision_threshold = predictor.calibrate_decision_threshold()\n",
        "predictor.set_decision_threshold(calibrated_decision_threshold)\n",
        "\n",
        "print(f'After calibration (predictor.decision_threshold={predictor.decision_threshold}):')\n",
        "scores_calibrated = predictor.evaluate(test_data)"
      ],
      "metadata": {
        "id": "10e6f148501e94c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb2d3c2-37bc-4a26-b647-3c0985c39a33"
      },
      "id": "10e6f148501e94c4"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision_threshold=0.250\t| metric=\"balanced_accuracy\"\n",
            "\ttest_score uncalibrated: 0.7438\n",
            "\ttest_score   calibrated: 0.8120\n",
            "\ttest_score        delta: 0.0682\n",
            "decision_threshold=0.250\t| metric=\"accuracy\"\n",
            "\ttest_score uncalibrated: 0.8472\n",
            "\ttest_score   calibrated: 0.8162\n",
            "\ttest_score        delta: -0.0310\n",
            "decision_threshold=0.250\t| metric=\"mcc\"\n",
            "\ttest_score uncalibrated: 0.5457\n",
            "\ttest_score   calibrated: 0.5654\n",
            "\ttest_score        delta: 0.0197\n",
            "decision_threshold=0.250\t| metric=\"roc_auc\"\n",
            "\ttest_score uncalibrated: 0.8990\n",
            "\ttest_score   calibrated: 0.8990\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.250\t| metric=\"f1\"\n",
            "\ttest_score uncalibrated: 0.6294\n",
            "\ttest_score   calibrated: 0.6749\n",
            "\ttest_score        delta: 0.0454\n",
            "decision_threshold=0.250\t| metric=\"precision\"\n",
            "\ttest_score uncalibrated: 0.7411\n",
            "\ttest_score   calibrated: 0.5814\n",
            "\ttest_score        delta: -0.1597\n",
            "decision_threshold=0.250\t| metric=\"recall\"\n",
            "\ttest_score uncalibrated: 0.5470\n",
            "\ttest_score   calibrated: 0.8041\n",
            "\ttest_score        delta: 0.2571\n"
          ]
        }
      ],
      "source": [
        "for metric_name in scores:\n",
        "    metric_score = scores[metric_name]\n",
        "    metric_score_calibrated = scores_calibrated[metric_name]\n",
        "    decision_threshold = predictor.decision_threshold\n",
        "    print(f'decision_threshold={decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n",
        "          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n",
        "          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n",
        "          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')"
      ],
      "metadata": {
        "id": "f18f7817111c6477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32faeb84-d234-4c99-9cef-52b2935cf073"
      },
      "id": "f18f7817111c6477"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that calibrating for \"balanced_accuracy\" majorly improved the \"balanced_accuracy\" metric score, but it harmed the \"accuracy\" score. Threshold calibration will often result in a tradeoff between performance on different metrics, and the user should keep this in mind.\n",
        "\n",
        "Instead of calibrating for \"balanced_accuracy\" specifically, we can calibrate for any metric if we want to maximize the score of that metric:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9b689133a34fe3d9"
      },
      "id": "9b689133a34fe3d9"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating predictor.decision_threshold from 0.25 -> 0.5\n",
            "\tThis will impact how prediction probabilities are converted to predictions in binary classification.\n",
            "\tPrediction probabilities of the positive class >0.5 will be predicted as the positive class ( >50K). This can significantly impact metric scores.\n",
            "\tYou can update this value via `predictor.set_decision_threshold`.\n",
            "\tYou can calculate an optimal decision threshold on the validation data via `predictor.calibrate_decision_threshold()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision_threshold=0.500\t| metric=\"f1\"\n",
            "\ttest_score uncalibrated: 0.6294\n",
            "\ttest_score   calibrated: 0.6294\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.250\t| metric=\"balanced_accuracy\"\n",
            "\ttest_score uncalibrated: 0.7438\n",
            "\ttest_score   calibrated: 0.8120\n",
            "\ttest_score        delta: 0.0682\n",
            "decision_threshold=0.500\t| metric=\"mcc\"\n",
            "\ttest_score uncalibrated: 0.5457\n",
            "\ttest_score   calibrated: 0.5457\n",
            "\ttest_score        delta: 0.0000\n"
          ]
        }
      ],
      "source": [
        "predictor.set_decision_threshold(0.5)  # Reset decision threshold\n",
        "for metric_name in ['f1', 'balanced_accuracy', 'mcc']:\n",
        "    metric_score = predictor.evaluate(test_data, silent=True)[metric_name]\n",
        "    calibrated_decision_threshold = predictor.calibrate_decision_threshold(metric=metric_name, verbose=False)\n",
        "    metric_score_calibrated = predictor.evaluate(\n",
        "        test_data, decision_threshold=calibrated_decision_threshold, silent=True\n",
        "    )[metric_name]\n",
        "    print(f'decision_threshold={calibrated_decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n",
        "          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n",
        "          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n",
        "          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')"
      ],
      "metadata": {
        "id": "251a1bf30667c186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d5aff3-8c34-48c2-b240-1db7bb16bafb"
      },
      "id": "251a1bf30667c186"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of calibrating the decision threshold post-fit, you can have it automatically occur during the fit call by specifying the fit parameter `predictor.fit(..., calibrate_decision_threshold=True)`.\n",
        "\n",
        "Luckily, AutoGluon will automatically apply decision threshold calibration when beneficial, as the default value is `calibrate_decision_threshold=\"auto\"`. We recommend keeping this value as the default in most cases.\n",
        "\n",
        "Additional usage examples are below:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b6bbe09b403c54b9"
      },
      "id": "b6bbe09b403c54b9"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "source": [
        "# Will use the decision_threshold specified in `predictor.decision_threshold`, can be set via `predictor.set_decision_threshold`\n",
        "# y_pred = predictor.predict(test_data)\n",
        "# y_pred_08 = predictor.predict(test_data, decision_threshold=0.8)  # Specify a specific threshold to use only for this predict\n",
        "\n",
        "# y_pred_proba = predictor.predict_proba(test_data)\n",
        "# y_pred = predictor.predict_from_proba(y_pred_proba)  # Identical output to calling .predict(test_data)\n",
        "# y_pred_08 = predictor.predict_from_proba(y_pred_proba, decision_threshold=0.8)  # Identical output to calling .predict(test_data, decision_threshold=0.8)"
      ],
      "metadata": {
        "id": "6e24e98242a6398a"
      },
      "id": "6e24e98242a6398a"
    },
    {
      "cell_type": "markdown",
      "id": "be2b3534",
      "metadata": {
        "id": "be2b3534"
      },
      "source": [
        "## Prediction options (inference)\n",
        "\n",
        "Even if you've started a new Python session since last calling `fit()`, you can still load a previously trained predictor from disk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "67cc8c19",
      "metadata": {
        "id": "67cc8c19"
      },
      "outputs": [],
      "source": [
        "predictor = TabularPredictor.load(save_path)  # `predictor.path` is another way to get the relative path needed to later load predictor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13759fc5",
      "metadata": {
        "id": "13759fc5"
      },
      "source": [
        "Above `save_path` is the same folder previously passed to `TabularPredictor`, in which all the trained models have been saved. You can train easily models on one machine and deploy them on another. Simply copy the `save_path` folder to the new machine and specify its new path in `TabularPredictor.load()`.\n",
        "\n",
        "To find out the required feature columns to make predictions, call `predictor.features()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dc1d292a",
      "metadata": {
        "id": "dc1d292a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0ebc5f-e67e-4e8c-8fcf-493078dc747d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age',\n",
              " 'workclass',\n",
              " 'fnlwgt',\n",
              " 'education',\n",
              " 'education-num',\n",
              " 'marital-status',\n",
              " 'occupation',\n",
              " 'relationship',\n",
              " 'race',\n",
              " 'sex',\n",
              " 'capital-gain',\n",
              " 'capital-loss',\n",
              " 'hours-per-week',\n",
              " 'native-country']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "predictor.features()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91285570",
      "metadata": {
        "id": "91285570"
      },
      "source": [
        "We can make a prediction on an individual example rather than a full dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2b5df1ea",
      "metadata": {
        "id": "2b5df1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "c5066b56-7430-496d-be80-955829859eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age workclass  fnlwgt education  education-num       marital-status  \\\n",
            "0   31   Private  169085      11th              7   Married-civ-spouse   \n",
            "\n",
            "  occupation relationship    race      sex  capital-gain  capital-loss  \\\n",
            "0      Sales         Wife   White   Female             0             0   \n",
            "\n",
            "   hours-per-week  native-country  \n",
            "0              20   United-States  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     <=50K\n",
              "Name: class, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "datapoint = test_data_nolabel.iloc[[0]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
        "print(datapoint)\n",
        "predictor.predict(datapoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f5e5d4c",
      "metadata": {
        "id": "7f5e5d4c"
      },
      "source": [
        "To output predicted class probabilities instead of predicted classes, you can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a9c88edf",
      "metadata": {
        "id": "a9c88edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "7c3f009b-d657-430b-9cdd-9abf294b3bb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      <=50K      >50K\n",
              "0  0.951059  0.048941"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91179e56-7f6e-4af6-9062-8923598f20ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&lt;=50K</th>\n",
              "      <th>&gt;50K</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.951059</td>\n",
              "      <td>0.048941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91179e56-7f6e-4af6-9062-8923598f20ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91179e56-7f6e-4af6-9062-8923598f20ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91179e56-7f6e-4af6-9062-8923598f20ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \" <=50K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9510592222213745,\n        \"max\": 0.9510592222213745,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9510592222213745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" >50K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0489407517015934,\n        \"max\": 0.0489407517015934,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0489407517015934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "predictor.predict_proba(datapoint)  # returns a DataFrame that shows which probability corresponds to which class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e118c312",
      "metadata": {
        "id": "e118c312"
      },
      "source": [
        "By default, `predict()` and `predict_proba()` will utilize the model that AutoGluon thinks is most accurate, which is usually an ensemble of many individual models. Here's how to see which model this is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "357da7e2",
      "metadata": {
        "id": "357da7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "45bbdae4-9ba3-4b3c-d597-e5ddae55d65b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WeightedEnsemble_L2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "predictor.model_best"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f47f3a",
      "metadata": {
        "id": "06f47f3a"
      },
      "source": [
        "We can instead specify a particular model to use for predictions (e.g. to reduce inference latency). Note that a 'model' in AutoGluon may refer to, for example, a single Neural Network, a bagged ensemble of many Neural Network copies trained on different training/validation splits, a weighted ensemble that aggregates the predictions of many other models, or a stacker model that operates on predictions output by other models. This is akin to viewing a Random Forest as one 'model' when it is in fact an ensemble of many decision trees.\n",
        "\n",
        "\n",
        "Before deciding which model to use, let's evaluate all of the models AutoGluon has previously trained on our test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d5f02254",
      "metadata": {
        "id": "d5f02254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "f815228d-d779-43ab-b730-300ae81018c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    model  score_test  score_val        eval_metric  \\\n",
              "0         LightGBM_BAG_L1    0.743784   0.776399  balanced_accuracy   \n",
              "1     WeightedEnsemble_L2    0.743784   0.776399  balanced_accuracy   \n",
              "2  NeuralNetFastAI_BAG_L1    0.728689   0.725071  balanced_accuracy   \n",
              "\n",
              "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
              "0        0.202149       0.064090   9.282016                 0.202149   \n",
              "1        0.203221       0.064651   9.300483                 0.001072   \n",
              "2        2.295429       0.054682  13.619211                 2.295429   \n",
              "\n",
              "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                0.064090           9.282016            1       True   \n",
              "1                0.000561           0.018467            2       True   \n",
              "2                0.054682          13.619211            1       True   \n",
              "\n",
              "   fit_order  \n",
              "0          1  \n",
              "1          3  \n",
              "2          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbd2af40-1386-46ec-b239-f6ac65f652b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.202149</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>0.202149</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.203221</td>\n",
              "      <td>0.064651</td>\n",
              "      <td>9.300483</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.728689</td>\n",
              "      <td>0.725071</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>2.295429</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>2.295429</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbd2af40-1386-46ec-b239-f6ac65f652b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbd2af40-1386-46ec-b239-f6ac65f652b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbd2af40-1386-46ec-b239-f6ac65f652b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f9c7839a-e94d-40ef-bb5c-a33cdb7b833c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9c7839a-e94d-40ef-bb5c-a33cdb7b833c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f9c7839a-e94d-40ef-bb5c-a33cdb7b833c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"LightGBM_BAG_L1\",\n          \"WeightedEnsemble_L2\",\n          \"NeuralNetFastAI_BAG_L1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008714883202075007,\n        \"min\": 0.7286894741358236,\n        \"max\": 0.7437840946238461,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7286894741358236,\n          0.7437840946238461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029633821780482274,\n        \"min\": 0.7250714045698925,\n        \"max\": 0.776398689516129,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7250714045698925,\n          0.776398689516129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"balanced_accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2082465640634787,\n        \"min\": 0.2021491527557373,\n        \"max\": 2.295429229736328,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.2021491527557373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005600696606507432,\n        \"min\": 0.054682016372680664,\n        \"max\": 0.0646512508392334,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06408977508544922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.498766971148709,\n        \"min\": 9.282016038894653,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.282016038894653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2705858320282548,\n        \"min\": 0.0010716915130615234,\n        \"max\": 2.295429229736328,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.2021491527557373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034286497966529356,\n        \"min\": 0.0005614757537841797,\n        \"max\": 0.06408977508544922,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06408977508544922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.947479861523583,\n        \"min\": 0.018466711044311523,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.282016038894653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "predictor.leaderboard(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11084a6a",
      "metadata": {
        "id": "11084a6a"
      },
      "source": [
        "The leaderboard shows each model's predictive performance on the test data (`score_test`) and validation data (`score_val`), as well as the time required to: produce predictions for the test data (`pred_time_val`), produce predictions on the validation data (`pred_time_val`), and train only this model (`fit_time`). Below, we show that a leaderboard can be produced without new data (just uses the data previously reserved for validation inside `fit`) and can display extra information about each model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2cd4b79f",
      "metadata": {
        "id": "2cd4b79f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "8e45216b-8ded-4c50-b923-b9117a014e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    model  score_val        eval_metric  pred_time_val  \\\n",
              "0         LightGBM_BAG_L1   0.776399  balanced_accuracy       0.064090   \n",
              "1     WeightedEnsemble_L2   0.776399  balanced_accuracy       0.064651   \n",
              "2  NeuralNetFastAI_BAG_L1   0.725071  balanced_accuracy       0.054682   \n",
              "\n",
              "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
              "0   9.282016                0.064090           9.282016            1   \n",
              "1   9.300483                0.000561           0.018467            2   \n",
              "2  13.619211                0.054682          13.619211            1   \n",
              "\n",
              "   can_infer  fit_order  ...  \\\n",
              "0       True          1  ...   \n",
              "1       True          3  ...   \n",
              "2       True          2  ...   \n",
              "\n",
              "                                                                                                                                                                            hyperparameters  \\\n",
              "0   {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'stratify': 'auto', 'bin': 'auto', 'n_bins': None}   \n",
              "1  {'use_orig_features': False, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'stratify': 'auto', 'bin': 'auto', 'n_bins': None}   \n",
              "2   {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'stratify': 'auto', 'bin': 'auto', 'n_bins': None}   \n",
              "\n",
              "   hyperparameters_fit  \\\n",
              "0                   {}   \n",
              "1                   {}   \n",
              "2                   {}   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                           ag_args_fit  \\\n",
              "0  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
              "1  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
              "2  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
              "\n",
              "                                                                                                                                                              features  \\\n",
              "0  [capital-loss, hours-per-week, occupation, race, relationship, marital-status, capital-gain, native-country, education-num, sex, education, workclass, fnlwgt, age]   \n",
              "1                                                                                                                                                    [LightGBM_BAG_L1]   \n",
              "2  [capital-loss, hours-per-week, occupation, race, relationship, marital-status, capital-gain, native-country, education-num, sex, education, workclass, fnlwgt, age]   \n",
              "\n",
              "   compile_time  \\\n",
              "0          None   \n",
              "1          None   \n",
              "2          None   \n",
              "\n",
              "                                                                                                                                                                             child_hyperparameters  \\\n",
              "0                                                                                                                                                  {'learning_rate': 0.05, 'num_boost_round': 200}   \n",
              "1                                                                                                                                                 {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
              "2  {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'num_epochs': 10}   \n",
              "\n",
              "         child_hyperparameters_fit  \\\n",
              "0          {'num_boost_round': 83}   \n",
              "1             {'ensemble_size': 1}   \n",
              "2  {'epochs': 30, 'best_epoch': 9}   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                             child_ag_args_fit  \\\n",
              "0                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
              "1                                          {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
              "2  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
              "\n",
              "           ancestors            descendants  \n",
              "0                 []  [WeightedEnsemble_L2]  \n",
              "1  [LightGBM_BAG_L1]                     []  \n",
              "2                 []                     []  \n",
              "\n",
              "[3 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df5fedd1-5758-4fad-984f-a3b7683a5728\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "      <th>...</th>\n",
              "      <th>hyperparameters</th>\n",
              "      <th>hyperparameters_fit</th>\n",
              "      <th>ag_args_fit</th>\n",
              "      <th>features</th>\n",
              "      <th>compile_time</th>\n",
              "      <th>child_hyperparameters</th>\n",
              "      <th>child_hyperparameters_fit</th>\n",
              "      <th>child_ag_args_fit</th>\n",
              "      <th>ancestors</th>\n",
              "      <th>descendants</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'stratify': 'auto', 'bin': 'auto', 'n_bins': None}</td>\n",
              "      <td>{}</td>\n",
              "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
              "      <td>[capital-loss, hours-per-week, occupation, race, relationship, marital-status, capital-gain, native-country, education-num, sex, education, workclass, fnlwgt, age]</td>\n",
              "      <td>None</td>\n",
              "      <td>{'learning_rate': 0.05, 'num_boost_round': 200}</td>\n",
              "      <td>{'num_boost_round': 83}</td>\n",
              "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
              "      <td>[]</td>\n",
              "      <td>[WeightedEnsemble_L2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.064651</td>\n",
              "      <td>9.300483</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>{'use_orig_features': False, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'stratify': 'auto', 'bin': 'auto', 'n_bins': None}</td>\n",
              "      <td>{}</td>\n",
              "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
              "      <td>[LightGBM_BAG_L1]</td>\n",
              "      <td>None</td>\n",
              "      <td>{'ensemble_size': 25, 'subsample_size': 1000000}</td>\n",
              "      <td>{'ensemble_size': 1}</td>\n",
              "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
              "      <td>[LightGBM_BAG_L1]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.725071</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'stratify': 'auto', 'bin': 'auto', 'n_bins': None}</td>\n",
              "      <td>{}</td>\n",
              "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
              "      <td>[capital-loss, hours-per-week, occupation, race, relationship, marital-status, capital-gain, native-country, education-num, sex, education, workclass, fnlwgt, age]</td>\n",
              "      <td>None</td>\n",
              "      <td>{'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'num_epochs': 10}</td>\n",
              "      <td>{'epochs': 30, 'best_epoch': 9}</td>\n",
              "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df5fedd1-5758-4fad-984f-a3b7683a5728')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df5fedd1-5758-4fad-984f-a3b7683a5728 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df5fedd1-5758-4fad-984f-a3b7683a5728');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-39517a37-d689-456e-9779-b123fa0b4803\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39517a37-d689-456e-9779-b123fa0b4803')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-39517a37-d689-456e-9779-b123fa0b4803 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "predictor.leaderboard(extra_info=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13dff991",
      "metadata": {
        "id": "13dff991"
      },
      "source": [
        "The expanded leaderboard shows properties like how many features are used by each model (`num_features`), which other models are ancestors whose predictions are required inputs for each model (`ancestors`), and how much memory each model and all its ancestors would occupy if simultaneously persisted (`memory_size_w_ancestors`). See the [leaderboard documentation](../../api/autogluon.tabular.TabularPredictor.leaderboard.rst) for full details.\n",
        "\n",
        "To show scores for other metrics, you can specify the `extra_metrics` argument when passing in `test_data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dc39b3b1",
      "metadata": {
        "id": "dc39b3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "f79780d0-7f29-4623-a769-f617ab276cca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    model  score_test  accuracy  balanced_accuracy  log_loss  \\\n",
              "0         LightGBM_BAG_L1    0.743784  0.847170           0.743784 -0.334022   \n",
              "1     WeightedEnsemble_L2    0.743784  0.847170           0.743784 -0.334022   \n",
              "2  NeuralNetFastAI_BAG_L1    0.728689  0.845225           0.728689 -0.344521   \n",
              "\n",
              "   score_val        eval_metric  pred_time_test  pred_time_val   fit_time  \\\n",
              "0   0.776399  balanced_accuracy        0.145196       0.064090   9.282016   \n",
              "1   0.776399  balanced_accuracy        0.146299       0.064651   9.300483   \n",
              "2   0.725071  balanced_accuracy        2.377695       0.054682  13.619211   \n",
              "\n",
              "   pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
              "0                 0.145196                0.064090           9.282016   \n",
              "1                 0.001103                0.000561           0.018467   \n",
              "2                 2.377695                0.054682          13.619211   \n",
              "\n",
              "   stack_level  can_infer  fit_order  \n",
              "0            1       True          1  \n",
              "1            2       True          3  \n",
              "2            1       True          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b5d2a2c-8d8c-4901-825a-bde237e63b89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>log_loss</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.847170</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>-0.334022</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.145196</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>0.145196</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.847170</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>-0.334022</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.146299</td>\n",
              "      <td>0.064651</td>\n",
              "      <td>9.300483</td>\n",
              "      <td>0.001103</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.728689</td>\n",
              "      <td>0.845225</td>\n",
              "      <td>0.728689</td>\n",
              "      <td>-0.344521</td>\n",
              "      <td>0.725071</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>2.377695</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>2.377695</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b5d2a2c-8d8c-4901-825a-bde237e63b89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b5d2a2c-8d8c-4901-825a-bde237e63b89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b5d2a2c-8d8c-4901-825a-bde237e63b89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4f58a6ca-5fbf-41ff-9b51-c8d97e123b67\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f58a6ca-5fbf-41ff-9b51-c8d97e123b67')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4f58a6ca-5fbf-41ff-9b51-c8d97e123b67 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"LightGBM_BAG_L1\",\n          \"WeightedEnsemble_L2\",\n          \"NeuralNetFastAI_BAG_L1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008714883202075007,\n        \"min\": 0.7286894741358236,\n        \"max\": 0.7437840946238461,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7286894741358236,\n          0.7437840946238461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0011229046079028059,\n        \"min\": 0.8452246903470161,\n        \"max\": 0.847169618179957,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8452246903470161,\n          0.847169618179957\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balanced_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008714883202075007,\n        \"min\": 0.7286894741358236,\n        \"max\": 0.7437840946238461,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7286894741358236,\n          0.7437840946238461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006061968605344458,\n        \"min\": -0.344521398047084,\n        \"max\": -0.33402176042873993,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.344521398047084,\n          -0.33402176042873993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029633821780482274,\n        \"min\": 0.7250714045698925,\n        \"max\": 0.776398689516129,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7250714045698925,\n          0.776398689516129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"balanced_accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.288615218745104,\n        \"min\": 0.14519643783569336,\n        \"max\": 2.377694606781006,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.14519643783569336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005600696606507432,\n        \"min\": 0.054682016372680664,\n        \"max\": 0.0646512508392334,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06408977508544922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.498766971148709,\n        \"min\": 9.282016038894653,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.282016038894653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3324789080222528,\n        \"min\": 0.0011026859283447266,\n        \"max\": 2.377694606781006,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.14519643783569336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034286497966529356,\n        \"min\": 0.0005614757537841797,\n        \"max\": 0.06408977508544922,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06408977508544922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.947479861523583,\n        \"min\": 0.018466711044311523,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.282016038894653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "predictor.leaderboard(test_data, extra_metrics=['accuracy', 'balanced_accuracy', 'log_loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b01083ae",
      "metadata": {
        "id": "b01083ae"
      },
      "source": [
        "Notice that `log_loss` scores are negative.\n",
        "This is because metrics in AutoGluon are always shown in `higher_is_better` form.\n",
        "This means that metrics such as `log_loss` and `root_mean_squared_error` will have their signs FLIPPED, and values will be negative.\n",
        "This is necessary to avoid the user needing to know the metric to understand if higher is better when looking at leaderboard.\n",
        "\n",
        "One additional caveat: It is possible that `log_loss` values can be `-inf` when computed via `extra_metrics`.\n",
        "This is because the models were not optimized with `log_loss` in mind during training and\n",
        "may have prediction probabilities giving a class `0` (particularly common with K-Nearest-Neighbors models).\n",
        "Because `log_loss` gives infinite error when the correct class was given `0` probability, this results in a score of `-inf`.\n",
        "It is therefore recommended that `log_loss` should not be used as a secondary metric to determine model quality.\n",
        "Either use `log_loss` as the `eval_metric` or avoid it altogether.\n",
        "\n",
        "Here's how to specify a particular model to use for prediction instead of AutoGluon's default model-choice:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1f938d89",
      "metadata": {
        "id": "1f938d89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68411b39-e21f-41cb-f4b2-b4cca1724887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction from LightGBM_BAG_L1 model:  <=50K\n"
          ]
        }
      ],
      "source": [
        "i = 0  # index of model to use\n",
        "model_to_use = predictor.model_names()[i]\n",
        "model_pred = predictor.predict(datapoint, model=model_to_use)\n",
        "print(\"Prediction from %s model: %s\" % (model_to_use, model_pred.iloc[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775cb4a5",
      "metadata": {
        "id": "775cb4a5"
      },
      "source": [
        "We can easily access various information about the trained predictor or a particular model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5cd13fed",
      "metadata": {
        "id": "5cd13fed"
      },
      "outputs": [],
      "source": [
        "all_models = predictor.model_names()\n",
        "model_to_use = all_models[i]\n",
        "specific_model = predictor._trainer.load_model(model_to_use)\n",
        "\n",
        "# Objects defined below are dicts of various information (not printed here as they are quite large):\n",
        "model_info = specific_model.get_info()\n",
        "predictor_information = predictor.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "640a8c38",
      "metadata": {
        "id": "640a8c38"
      },
      "source": [
        "The `predictor` also remembers what metric predictions should be evaluated with, which can be done with ground truth labels as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "39b53a65",
      "metadata": {
        "id": "39b53a65"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = predictor.predict_proba(test_data_nolabel)\n",
        "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2932b36",
      "metadata": {
        "id": "f2932b36"
      },
      "source": [
        "Since the label columns remains in the `test_data` DataFrame, we can instead use the shorthand:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5494aae6",
      "metadata": {
        "id": "5494aae6"
      },
      "outputs": [],
      "source": [
        "perf = predictor.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02223a4e",
      "metadata": {
        "id": "02223a4e"
      },
      "source": [
        "## Interpretability (feature importance)\n",
        "\n",
        "To better understand our trained predictor, we can estimate the overall importance of each feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "82ffd4bd",
      "metadata": {
        "id": "82ffd4bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "76f8dd9e-08a6-48cf-f780-895e4137c8e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing feature importance via permutation shuffling for 14 features using 5000 rows with 5 shuffle sets...\n",
            "\t13.25s\t= Expected runtime (2.65s per shuffle set)\n",
            "\t6.91s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                importance    stddev       p_value  n  p99_high   p99_low\n",
              "marital-status    0.068704  0.004542  2.279366e-06  5  0.078057  0.059352\n",
              "capital-gain      0.046431  0.002457  9.369035e-07  5  0.051489  0.041372\n",
              "education-num     0.042721  0.003485  5.268617e-06  5  0.049898  0.035545\n",
              "age               0.035115  0.005922  9.348413e-05  5  0.047308  0.022922\n",
              "occupation        0.033699  0.007890  3.356604e-04  5  0.049945  0.017454\n",
              "relationship      0.014965  0.003663  3.983866e-04  5  0.022507  0.007423\n",
              "hours-per-week    0.012270  0.003750  9.287608e-04  5  0.019992  0.004548\n",
              "capital-loss      0.002217  0.001260  8.531892e-03  5  0.004812 -0.000378\n",
              "education         0.000319  0.000774  2.045314e-01  5  0.001912 -0.001274\n",
              "native-country    0.000000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
              "race             -0.000256  0.000268  9.500382e-01  5  0.000296 -0.000807\n",
              "sex              -0.000527  0.001303  7.914146e-01  5  0.002156 -0.003210\n",
              "workclass        -0.001594  0.002576  8.807408e-01  5  0.003709 -0.006898\n",
              "fnlwgt           -0.004992  0.001524  9.990763e-01  5 -0.001855 -0.008130"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ac35f7c-39c5-465e-a7b0-06d99e29c645\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>marital-status</th>\n",
              "      <td>0.068704</td>\n",
              "      <td>0.004542</td>\n",
              "      <td>2.279366e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.078057</td>\n",
              "      <td>0.059352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gain</th>\n",
              "      <td>0.046431</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>9.369035e-07</td>\n",
              "      <td>5</td>\n",
              "      <td>0.051489</td>\n",
              "      <td>0.041372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education-num</th>\n",
              "      <td>0.042721</td>\n",
              "      <td>0.003485</td>\n",
              "      <td>5.268617e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.049898</td>\n",
              "      <td>0.035545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0.035115</td>\n",
              "      <td>0.005922</td>\n",
              "      <td>9.348413e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.047308</td>\n",
              "      <td>0.022922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>occupation</th>\n",
              "      <td>0.033699</td>\n",
              "      <td>0.007890</td>\n",
              "      <td>3.356604e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.049945</td>\n",
              "      <td>0.017454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relationship</th>\n",
              "      <td>0.014965</td>\n",
              "      <td>0.003663</td>\n",
              "      <td>3.983866e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.022507</td>\n",
              "      <td>0.007423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hours-per-week</th>\n",
              "      <td>0.012270</td>\n",
              "      <td>0.003750</td>\n",
              "      <td>9.287608e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.019992</td>\n",
              "      <td>0.004548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0.002217</td>\n",
              "      <td>0.001260</td>\n",
              "      <td>8.531892e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>-0.000378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education</th>\n",
              "      <td>0.000319</td>\n",
              "      <td>0.000774</td>\n",
              "      <td>2.045314e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.001912</td>\n",
              "      <td>-0.001274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>native-country</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race</th>\n",
              "      <td>-0.000256</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>9.500382e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>-0.000807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>-0.000527</td>\n",
              "      <td>0.001303</td>\n",
              "      <td>7.914146e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.002156</td>\n",
              "      <td>-0.003210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>workclass</th>\n",
              "      <td>-0.001594</td>\n",
              "      <td>0.002576</td>\n",
              "      <td>8.807408e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.003709</td>\n",
              "      <td>-0.006898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fnlwgt</th>\n",
              "      <td>-0.004992</td>\n",
              "      <td>0.001524</td>\n",
              "      <td>9.990763e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.001855</td>\n",
              "      <td>-0.008130</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ac35f7c-39c5-465e-a7b0-06d99e29c645')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ac35f7c-39c5-465e-a7b0-06d99e29c645 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ac35f7c-39c5-465e-a7b0-06d99e29c645');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7e3325f5-3a72-40cb-ab5c-7920a1026a4b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e3325f5-3a72-40cb-ab5c-7920a1026a4b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7e3325f5-3a72-40cb-ab5c-7920a1026a4b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023280955972365208,\n        \"min\": -0.004992191311829375,\n        \"max\": 0.0687044787381482,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0,\n          -0.0005267724867012546,\n          0.0687044787381482\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stddev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022458220990253445,\n        \"min\": 0.0,\n        \"max\": 0.007889956701415103,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0,\n          0.0013031499184173467,\n          0.004542291025061033\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.416181599112621,\n        \"min\": 9.369035299375961e-07,\n        \"max\": 0.9990762589548124,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.5,\n          0.7914146046506543,\n          2.2793658812670262e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p99_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026504115443328476,\n        \"min\": -0.0018547910082743662,\n        \"max\": 0.07805711873988264,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p99_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02059863453303265,\n        \"min\": -0.008129591615384384,\n        \"max\": 0.05935183873641375,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "predictor.feature_importance(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "954655e5",
      "metadata": {
        "id": "954655e5"
      },
      "source": [
        "Computed via [permutation-shuffling](https://explained.ai/rf-importance/), these feature importance scores quantify the drop in predictive performance (of the already trained predictor) when one column's values are randomly shuffled across rows. The top features in this list contribute most to AutoGluon's accuracy (for predicting when/if a patient will be readmitted to the hospital). Features with non-positive importance score hardly contribute to the predictor's accuracy, or may even be actively harmful to include in the data (consider removing these features from your data and calling `fit` again). These scores facilitate interpretability of the predictor's global behavior (which features it relies on for *all* predictions).\n",
        "To get [local explanations](https://christophm.github.io/interpretable-ml-book/taxonomy-of-interpretability-methods.html) regarding which features influence a *particular* prediction, check out the [example notebooks](https://github.com/autogluon/autogluon/tree/master/examples/tabular/interpret) for explaining particular AutoGluon predictions using [Shapely values](https://github.com/slundberg/shap/).\n",
        "\n",
        "Before making judgement on if AutoGluon is more or less interpretable than another solution, we recommend reading [The Mythos of Model Interpretability](https://dl.acm.org/doi/pdf/10.1145/3236386.3241340) by Zachary Lipton, which covers why often-claimed interpretable models such as trees and linear models are rarely meaningfully more interpretable than more advanced models.\n",
        "\n",
        "## Accelerating inference\n",
        "\n",
        "We describe multiple ways to reduce the time it takes for AutoGluon to produce predictions.\n",
        "\n",
        "Before providing code examples, it is important to understand that\n",
        "there are several ways to accelerate inference in AutoGluon. The table below lists the options in order of priority.\n",
        "\n",
        "| Optimization                      | Inference Speedup                                                                                     | Cost                              | Notes                                                                                                                                                                                  |\n",
        "|:----------------------------------|:------------------------------------------------------------------------------------------------------|:----------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| refit_full                        | At least 8x+, up to 160x (requires bagging)                                                           | -Quality, +FitTime                | Only provides speedup with bagging enabled.                                                                                                                                            |\n",
        "| persist                           | Up to 10x in online-inference                                                                         | ++MemoryUsage                     | If memory is not sufficient to persist model, speedup is not gained. Speedup is most effective in online-inference and is not relevant in batch inference.                             |\n",
        "| infer_limit                       | Configurable, ~up to 50x                                                                              | -Quality (Relative to speedup)    | If bagging is enabled, always use refit_full if using infer_limit.                                                                                                                     |\n",
        "| distill                           | ~Equals combined speedup of refit_full and infer_limit set to extreme values                          | --Quality, ++FitTime              | Not compatible with refit_full and infer_limit.                                                                                                                                        |\n",
        "| feature pruning                   | Typically at most 1.5x. More if willing to lower quality significantly.                               | -Quality?, ++FitTime              | Dependent on the existence of unimportant features in data. Call `predictor.feature_importance(test_data)` to gauge which features could be removed.                                   |\n",
        "| use faster hardware               | Usually at most 3x. Depends on hardware (ignoring GPU).                                               | +Hardware                         | As an example, an EC2 c6i.2xlarge is ~1.6x faster than an m5.2xlarge for a similar price. Laptops in particular might be slow compared to cloud instances.                             |\n",
        "| manual hyperparameters adjustment | Usually at most 2x assuming infer_limit is already specified.                                         | ---Quality?, +++UserMLExpertise   | Can be very complicated and is not recommended. Potential ways to get speedups this way is to reduce the number of trees in LightGBM, XGBoost, CatBoost, RandomForest, and ExtraTrees. |\n",
        "| manual data preprocessing         | Usually at most 1.2x assuming all other optimizations are specified and setting is online-inference.  | ++++UserMLExpertise, ++++UserCode | Only relevant for online-inference. This is not recommended as AutoGluon's default preprocessing is highly optimized.                                                                  |\n",
        "\n",
        "If bagging is enabled (num_bag_folds>0 or num_stack_levels>0 or using 'best_quality' preset), the order of inference optimizations should be:  \n",
        "1. refit_full  \n",
        "2. persist  \n",
        "3. infer_limit  \n",
        "\n",
        "If bagging is not enabled (num_bag_folds=0, num_stack_levels=0), the order of inference optimizations should be:  \n",
        "1. persist  \n",
        "2. infer_limit  \n",
        "\n",
        "If following these recommendations does not lead to a sufficiently fast model, you may consider the more advanced options in the table.\n",
        "\n",
        "### Keeping models in memory\n",
        "\n",
        "By default, AutoGluon loads models into memory one at a time and only when they are needed for prediction. This strategy is robust for large stacked/bagged ensembles, but leads to slower prediction times. If you plan to repeatedly make predictions (e.g. on new datapoints one at a time rather than one large test dataset), you can first specify that all models required for inference should be loaded into memory as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e2eced22",
      "metadata": {
        "id": "e2eced22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d21821-7c77-4d2d-9453-76bece4df47a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Persisting 2 models in memory. Models will require 0.0% of memory.\n",
            "Unpersisted 2 models: ['WeightedEnsemble_L2', 'LightGBM_BAG_L1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:  [' <=50K' ' <=50K' ' >50K' ' <=50K' ' <=50K' ' >50K' ' >50K' ' >50K'\n",
            " ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K'\n",
            " ' <=50K' ' >50K' ' >50K' ' <=50K']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['WeightedEnsemble_L2', 'LightGBM_BAG_L1']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "predictor.persist()\n",
        "\n",
        "num_test = 20\n",
        "preds = np.array(['']*num_test, dtype='object')\n",
        "for i in range(num_test):\n",
        "    datapoint = test_data_nolabel.iloc[[i]]\n",
        "    pred_numpy = predictor.predict(datapoint, as_pandas=False)\n",
        "    preds[i] = pred_numpy[0]\n",
        "\n",
        "perf = predictor.evaluate_predictions(y_test[:num_test], preds, auxiliary_metrics=True)\n",
        "print(\"Predictions: \", preds)\n",
        "\n",
        "predictor.unpersist()  # free memory by clearing models, future predict() calls will load models from disk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec079f09",
      "metadata": {
        "id": "ec079f09"
      },
      "source": [
        "You can alternatively specify a particular model to persist via the `models` argument of `persist()`, or simply set `models='all'` to simultaneously load every single model that was trained during `fit`.\n",
        "\n",
        "### Inference speed as a fit constraint\n",
        "\n",
        "If you know your latency constraint prior to fitting the predictor, you can specify it explicitly as a fit argument.\n",
        "AutoGluon will then automatically train models in a fashion that attempts to satisfy the constraint.\n",
        "\n",
        "This constraint has two components: `infer_limit` and `infer_limit_batch_size`:  \n",
        "- `infer_limit` is the time in seconds to predict 1 row of data.\n",
        "For example, `infer_limit=0.05` means 50 ms per row of data,\n",
        "or 20 rows / second throughput.  \n",
        "- `infer_limit_batch_size` is the amount of rows passed at once to predict when calculating per-row speed.\n",
        "This is very important because `infer_limit_batch_size=1` (online-inference) is highly suboptimal as\n",
        "various operations have a fixed cost overhead regardless of data size. If you can pass your test data in bulk,\n",
        "you should specify `infer_limit_batch_size=10000`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c845d3cd",
      "metadata": {
        "id": "c845d3cd",
        "outputId": "59c62ab0-fb0a-4b3f-8b90-3ce90b6a935a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251018_192100\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          4\n",
            "Memory Avail:       43.93 GB / 47.05 GB (93.4%)\n",
            "Disk Space Avail:   196.82 GB / 225.33 GB (87.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251018_192100\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    44981.14 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.50 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "\t1.164μs\t= Feature Preprocessing Time (1 row | 10000 batch size)\n",
            "\t\tFeature Preprocessing requires 2.33% of the overall inference constraint (0.05ms)\n",
            "\t\t0.049ms inference time budget remaining for models...\n",
            "Data preprocessing and feature engineering runtime = 0.19s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 29.81s of the 29.81s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.9 GB\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t1.482μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t1.482μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t1.482μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t1.482μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: LightGBM ... Training model for up to 29.30s of the 29.30s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.9 GB\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.5s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t1.415μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t1.415μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t1.415μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t1.415μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: RandomForestGini ... Training model for up to 28.79s of the 28.79s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "\t5.475μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t5.475μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t5.475μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t5.475μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: RandomForestEntr ... Training model for up to 28.17s of the 28.17s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.835\t = Validation score   (accuracy)\n",
            "\t0.45s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "\t5.455μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t5.455μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t5.455μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t5.455μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: CatBoost ... Training model for up to 27.66s of the 27.66s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.86\t = Validation score   (accuracy)\n",
            "\t3.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t0.59μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t0.59μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.59μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t0.59μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 24.27s of the 24.27s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.815\t = Validation score   (accuracy)\n",
            "\t0.49s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "\t6.696μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t6.696μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t6.696μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t6.696μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 23.72s of the 23.72s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.82\t = Validation score   (accuracy)\n",
            "\t0.49s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "\t6.523μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t6.523μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t6.523μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t6.523μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 23.17s of the 23.17s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.9 GB\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t9.176μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t9.176μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t9.176μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t9.176μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: XGBoost ... Training model for up to 22.33s of the 22.33s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.855\t = Validation score   (accuracy)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t1.526μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t1.526μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t1.526μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t1.526μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 21.99s of the 21.99s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.9 GB\n",
            "\t0.855\t = Validation score   (accuracy)\n",
            "\t3.05s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t3.713μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t3.713μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t3.713μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t3.713μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: LightGBMLarge ... Training model for up to 18.93s of the 18.93s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.8 GB\n",
            "\t0.795\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t6.733μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t6.733μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t6.733μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t6.733μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Removing 1/11 base models to satisfy inference constraint (constraint=0.046ms) ...\n",
            "\t0.049ms\t-> 0.042ms\t(LightGBMLarge)\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.81s of the 17.91s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestGini': 0.429, 'CatBoost': 0.286, 'LightGBMXT': 0.143, 'ExtraTreesEntr': 0.143}\n",
            "\t0.875\t = Validation score   (accuracy)\n",
            "\t0.07s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t0.103μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t0.014ms\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.103μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t0.014ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "AutoGluon training complete, total runtime = 12.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2092.0 rows/s (200 batch size)\n",
            "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (200 rows).\n",
            "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251018_192100\")\n",
            "Persisting 5 models in memory. Models will require 0.03% of memory.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  model  score_val eval_metric  pred_time_val  fit_time  \\\n",
              "0   WeightedEnsemble_L2      0.875    accuracy       0.095603  4.931657   \n",
              "1              CatBoost      0.860    accuracy       0.002528  3.379452   \n",
              "2               XGBoost      0.855    accuracy       0.003990  0.328219   \n",
              "3        NeuralNetTorch      0.855    accuracy       0.007939  3.046063   \n",
              "4            LightGBMXT      0.850    accuracy       0.002390  0.431277   \n",
              "5       NeuralNetFastAI      0.850    accuracy       0.006258  0.821118   \n",
              "6              LightGBM      0.840    accuracy       0.002026  0.502453   \n",
              "7      RandomForestGini      0.840    accuracy       0.045413  0.564555   \n",
              "8      RandomForestEntr      0.835    accuracy       0.044644  0.447293   \n",
              "9        ExtraTreesEntr      0.820    accuracy       0.044675  0.488697   \n",
              "10       ExtraTreesGini      0.815    accuracy       0.044863  0.489513   \n",
              "11        LightGBMLarge      0.795    accuracy       0.003652  0.973265   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                 0.000597           0.067676            2       True   \n",
              "1                 0.002528           3.379452            1       True   \n",
              "2                 0.003990           0.328219            1       True   \n",
              "3                 0.007939           3.046063            1       True   \n",
              "4                 0.002390           0.431277            1       True   \n",
              "5                 0.006258           0.821118            1       True   \n",
              "6                 0.002026           0.502453            1       True   \n",
              "7                 0.045413           0.564555            1       True   \n",
              "8                 0.044644           0.447293            1       True   \n",
              "9                 0.044675           0.488697            1       True   \n",
              "10                0.044863           0.489513            1       True   \n",
              "11                0.003652           0.973265            1       True   \n",
              "\n",
              "    fit_order  \n",
              "0          12  \n",
              "1           5  \n",
              "2           9  \n",
              "3          10  \n",
              "4           1  \n",
              "5           8  \n",
              "6           2  \n",
              "7           3  \n",
              "8           4  \n",
              "9           7  \n",
              "10          6  \n",
              "11         11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bac5820e-3599-42ba-8536-7de9c1ae4276\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.875</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.095603</td>\n",
              "      <td>4.931657</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>0.067676</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.860</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.002528</td>\n",
              "      <td>3.379452</td>\n",
              "      <td>0.002528</td>\n",
              "      <td>3.379452</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.855</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.003990</td>\n",
              "      <td>0.328219</td>\n",
              "      <td>0.003990</td>\n",
              "      <td>0.328219</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>0.855</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.007939</td>\n",
              "      <td>3.046063</td>\n",
              "      <td>0.007939</td>\n",
              "      <td>3.046063</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.850</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.002390</td>\n",
              "      <td>0.431277</td>\n",
              "      <td>0.002390</td>\n",
              "      <td>0.431277</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>0.850</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.006258</td>\n",
              "      <td>0.821118</td>\n",
              "      <td>0.006258</td>\n",
              "      <td>0.821118</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.840</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.002026</td>\n",
              "      <td>0.502453</td>\n",
              "      <td>0.002026</td>\n",
              "      <td>0.502453</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForestGini</td>\n",
              "      <td>0.840</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.045413</td>\n",
              "      <td>0.564555</td>\n",
              "      <td>0.045413</td>\n",
              "      <td>0.564555</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForestEntr</td>\n",
              "      <td>0.835</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.044644</td>\n",
              "      <td>0.447293</td>\n",
              "      <td>0.044644</td>\n",
              "      <td>0.447293</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ExtraTreesEntr</td>\n",
              "      <td>0.820</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.044675</td>\n",
              "      <td>0.488697</td>\n",
              "      <td>0.044675</td>\n",
              "      <td>0.488697</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ExtraTreesGini</td>\n",
              "      <td>0.815</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.044863</td>\n",
              "      <td>0.489513</td>\n",
              "      <td>0.044863</td>\n",
              "      <td>0.489513</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>0.795</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.003652</td>\n",
              "      <td>0.973265</td>\n",
              "      <td>0.003652</td>\n",
              "      <td>0.973265</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bac5820e-3599-42ba-8536-7de9c1ae4276')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bac5820e-3599-42ba-8536-7de9c1ae4276 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bac5820e-3599-42ba-8536-7de9c1ae4276');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-55eafbff-e1a6-4564-b361-f2405b13ae25\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55eafbff-e1a6-4564-b361-f2405b13ae25')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-55eafbff-e1a6-4564-b361-f2405b13ae25 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor_infer_limit\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"ExtraTreesGini\",\n          \"ExtraTreesEntr\",\n          \"WeightedEnsemble_L2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02203647114685245,\n        \"min\": 0.795,\n        \"max\": 0.875,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.815,\n          0.86,\n          0.835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029620634325389455,\n        \"min\": 0.002026081085205078,\n        \"max\": 0.09560346603393555,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.04486274719238281\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5303675869654347,\n        \"min\": 0.3282191753387451,\n        \"max\": 4.931657314300537,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.4895133972167969\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02038884021197009,\n        \"min\": 0.0005967617034912109,\n        \"max\": 0.04541349411010742,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.04486274719238281\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0775331661165308,\n        \"min\": 0.06767630577087402,\n        \"max\": 3.3794519901275635,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.4895133972167969\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# At most 0.05 ms per row (20000 rows per second throughput)\n",
        "infer_limit = 0.00005\n",
        "# adhere to infer_limit with batches of size 10000 (batch-inference, easier to satisfy infer_limit)\n",
        "infer_limit_batch_size = 10000\n",
        "# adhere to infer_limit with batches of size 1 (online-inference, much harder to satisfy infer_limit)\n",
        "# infer_limit_batch_size = 1  # Note that infer_limit<0.02 when infer_limit_batch_size=1 can be difficult to satisfy.\n",
        "predictor_infer_limit = TabularPredictor(label=label, eval_metric=metric).fit(\n",
        "    train_data=train_data,\n",
        "    time_limit=30,\n",
        "    infer_limit=infer_limit,\n",
        "    infer_limit_batch_size=infer_limit_batch_size,\n",
        ")\n",
        "\n",
        "# NOTE: If bagging was enabled, it is important to call refit_full at this stage.\n",
        "#  infer_limit assumes that the user will call refit_full after fit.\n",
        "# predictor_infer_limit.refit_full()\n",
        "\n",
        "# NOTE: To align with inference speed calculated during fit, models must be persisted.\n",
        "predictor_infer_limit.persist()\n",
        "# Below is an optimized version that only persists the minimum required models for prediction.\n",
        "# predictor_infer_limit.persist('best')\n",
        "\n",
        "predictor_infer_limit.leaderboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a69ab0da",
      "metadata": {
        "id": "a69ab0da"
      },
      "source": [
        "Now we can test the inference speed of the final model and check if it satisfies the inference constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0a668eac",
      "metadata": {
        "id": "0a668eac",
        "outputId": "8dee76e0-bb53-47ad-84ef-a8b99413a7b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is able to predict 64643.4 rows per second. (User-specified Throughput = 20000.0)\n",
            "Model uses 30.9% of infer_limit time per row.\n",
            "Model satisfies inference constraint: True\n"
          ]
        }
      ],
      "source": [
        "test_data_batch = test_data.sample(infer_limit_batch_size, replace=True, ignore_index=True)\n",
        "\n",
        "import time\n",
        "time_start = time.time()\n",
        "predictor_infer_limit.predict(test_data_batch)\n",
        "time_end = time.time()\n",
        "\n",
        "infer_time_per_row = (time_end - time_start) / len(test_data_batch)\n",
        "rows_per_second = 1 / infer_time_per_row\n",
        "infer_time_per_row_ratio = infer_time_per_row / infer_limit\n",
        "is_constraint_satisfied = infer_time_per_row_ratio <= 1\n",
        "\n",
        "print(f'Model is able to predict {round(rows_per_second, 1)} rows per second. (User-specified Throughput = {1 / infer_limit})')\n",
        "print(f'Model uses {round(infer_time_per_row_ratio * 100, 1)}% of infer_limit time per row.')\n",
        "print(f'Model satisfies inference constraint: {is_constraint_satisfied}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d988fa3",
      "metadata": {
        "id": "9d988fa3"
      },
      "source": [
        "### Using smaller ensemble or faster model for prediction\n",
        "\n",
        "Without having to retrain any models, one can construct alternative ensembles that aggregate individual models' predictions with different weighting schemes. These ensembles become smaller (and hence faster for prediction) if they assign nonzero weight to less models. You can produce a wide variety of ensembles with different accuracy-speed tradeoffs like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1dcda6fd",
      "metadata": {
        "id": "1dcda6fd",
        "outputId": "ce2ebc17-fa12-427a-9bec-9b01a809a69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting model: WeightedEnsemble_L2Best ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.7764\t = Validation score   (balanced_accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternative ensembles you can use for prediction: ['WeightedEnsemble_L2Best']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    model  score_val        eval_metric  pred_time_val  \\\n",
              "0         LightGBM_BAG_L1   0.776399  balanced_accuracy       0.064090   \n",
              "1  NeuralNetFastAI_BAG_L1   0.725071  balanced_accuracy       0.054682   \n",
              "\n",
              "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
              "0   9.282016                0.064090           9.282016            1   \n",
              "1  13.619211                0.054682          13.619211            1   \n",
              "\n",
              "   can_infer  fit_order  \n",
              "0       True          1  \n",
              "1       True          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec78057c-a168-4cdf-ad2a-d238b1bef968\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.725071</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec78057c-a168-4cdf-ad2a-d238b1bef968')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec78057c-a168-4cdf-ad2a-d238b1bef968 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec78057c-a168-4cdf-ad2a-d238b1bef968');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3812de11-e315-455b-96d8-841c466e30c3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3812de11-e315-455b-96d8-841c466e30c3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3812de11-e315-455b-96d8-841c466e30c3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NeuralNetFastAI_BAG_L1\",\n          \"LightGBM_BAG_L1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03629387124537803,\n        \"min\": 0.7250714045698925,\n        \"max\": 0.776398689516129,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7250714045698925,\n          0.776398689516129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"balanced_accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00665228998156547,\n        \"min\": 0.054682016372680664,\n        \"max\": 0.06408977508544922,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.054682016372680664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.066860107554626,\n        \"min\": 9.282016038894653,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          13.619211196899414\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00665228998156547,\n        \"min\": 0.054682016372680664,\n        \"max\": 0.06408977508544922,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.054682016372680664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.066860107554626,\n        \"min\": 9.282016038894653,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          13.619211196899414\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "additional_ensembles = predictor.fit_weighted_ensemble(expand_pareto_frontier=True)\n",
        "print(\"Alternative ensembles you can use for prediction:\", additional_ensembles)\n",
        "\n",
        "predictor.leaderboard(only_pareto_frontier=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd8fe52",
      "metadata": {
        "id": "edd8fe52"
      },
      "source": [
        "The resulting leaderboard will contain the most accurate model for a given inference-latency. You can select whichever model exhibits acceptable latency from the leaderboard and use it for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a757a79b",
      "metadata": {
        "id": "a757a79b",
        "outputId": "54fc8ae0-7c56-41b4-f144-dcc248f15ac9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Deleting model WeightedEnsemble_L2Best. All files under /content/agModels-predictClass/models/WeightedEnsemble_L2Best will be removed.\n"
          ]
        }
      ],
      "source": [
        "model_for_prediction = additional_ensembles[0]\n",
        "predictions = predictor.predict(test_data, model=model_for_prediction)\n",
        "predictor.delete_models(models_to_delete=additional_ensembles, dry_run=False)  # delete these extra models so they don't affect rest of tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9158cc13",
      "metadata": {
        "id": "9158cc13"
      },
      "source": [
        "### Collapsing bagged ensembles via refit_full\n",
        "\n",
        "For an ensemble predictor trained with bagging (as done above), recall there are ~10 bagged copies of each individual model trained on different train/validation folds. We can collapse this bag of ~10 models into a single model that's fit to the full dataset, which can greatly reduce its memory/latency requirements (but may also reduce accuracy). Below we refit such a model for each original model but you can alternatively do this for just a particular model by specifying the `model` argument of `refit_full()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "fd8ea890",
      "metadata": {
        "id": "fd8ea890",
        "outputId": "c3e107bd-4b58-4d88-aeaa-c322a0c34a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t0.27s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
            "Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
            "\tStopping at the best epoch learned earlier - 9.\n",
            "\t0.28s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.02s\t = Training   runtime\n",
            "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 0.61s ... Best model: \"WeightedEnsemble_L2_FULL\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name of each refit-full model corresponding to a previous bagged ensemble:\n",
            "{'LightGBM_BAG_L1': 'LightGBM_BAG_L1_FULL', 'NeuralNetFastAI_BAG_L1': 'NeuralNetFastAI_BAG_L1_FULL', 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         model  score_test  score_val        eval_metric  \\\n",
              "0         LightGBM_BAG_L1_FULL    0.750092        NaN  balanced_accuracy   \n",
              "1     WeightedEnsemble_L2_FULL    0.750092        NaN  balanced_accuracy   \n",
              "2              LightGBM_BAG_L1    0.743784   0.776399  balanced_accuracy   \n",
              "3          WeightedEnsemble_L2    0.743784   0.776399  balanced_accuracy   \n",
              "4       NeuralNetFastAI_BAG_L1    0.728689   0.725071  balanced_accuracy   \n",
              "5  NeuralNetFastAI_BAG_L1_FULL    0.709449        NaN  balanced_accuracy   \n",
              "\n",
              "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
              "0        0.017124            NaN   0.268760                 0.017124   \n",
              "1        0.018170            NaN   0.287227                 0.001045   \n",
              "2        0.147630       0.064090   9.282016                 0.147630   \n",
              "3        0.148695       0.064651   9.300483                 0.001065   \n",
              "4        0.735530       0.054682  13.619211                 0.735530   \n",
              "5        0.092940            NaN   0.284884                 0.092940   \n",
              "\n",
              "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                     NaN           0.268760            1       True   \n",
              "1                     NaN           0.018467            2       True   \n",
              "2                0.064090           9.282016            1       True   \n",
              "3                0.000561           0.018467            2       True   \n",
              "4                0.054682          13.619211            1       True   \n",
              "5                     NaN           0.284884            1       True   \n",
              "\n",
              "   fit_order  \n",
              "0          4  \n",
              "1          6  \n",
              "2          1  \n",
              "3          3  \n",
              "4          2  \n",
              "5          5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-104320f4-d260-4882-8e1b-c0e5707b3fc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1_FULL</td>\n",
              "      <td>0.750092</td>\n",
              "      <td>NaN</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.017124</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.268760</td>\n",
              "      <td>0.017124</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.268760</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2_FULL</td>\n",
              "      <td>0.750092</td>\n",
              "      <td>NaN</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.018170</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.287227</td>\n",
              "      <td>0.001045</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.147630</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>0.147630</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.148695</td>\n",
              "      <td>0.064651</td>\n",
              "      <td>9.300483</td>\n",
              "      <td>0.001065</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.728689</td>\n",
              "      <td>0.725071</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.735530</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>0.735530</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
              "      <td>0.709449</td>\n",
              "      <td>NaN</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.092940</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.284884</td>\n",
              "      <td>0.092940</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.284884</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-104320f4-d260-4882-8e1b-c0e5707b3fc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-104320f4-d260-4882-8e1b-c0e5707b3fc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-104320f4-d260-4882-8e1b-c0e5707b3fc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0257833b-0ed3-4586-9eac-f8c0b2fc9f2b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0257833b-0ed3-4586-9eac-f8c0b2fc9f2b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0257833b-0ed3-4586-9eac-f8c0b2fc9f2b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"LightGBM_BAG_L1_FULL\",\n          \"WeightedEnsemble_L2_FULL\",\n          \"NeuralNetFastAI_BAG_L1_FULL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015877607148799985,\n        \"min\": 0.7094486104151958,\n        \"max\": 0.7500924359540138,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7437840946238461,\n          0.7094486104151958,\n          0.7500924359540138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029633821780482274,\n        \"min\": 0.7250714045698925,\n        \"max\": 0.776398689516129,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7250714045698925,\n          0.776398689516129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"balanced_accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2719815276590507,\n        \"min\": 0.017124176025390625,\n        \"max\": 0.7355303764343262,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.017124176025390625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005600696606507432,\n        \"min\": 0.054682016372680664,\n        \"max\": 0.0646512508392334,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06408977508544922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.939779682649337,\n        \"min\": 0.26875996589660645,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.26875996589660645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2851727143922727,\n        \"min\": 0.0010454654693603516,\n        \"max\": 0.7355303764343262,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.017124176025390625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034286497966529356,\n        \"min\": 0.0005614757537841797,\n        \"max\": 0.06408977508544922,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06408977508544922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.996921308803457,\n        \"min\": 0.018466711044311523,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.018466711044311523\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "refit_model_map = predictor.refit_full()\n",
        "print(\"Name of each refit-full model corresponding to a previous bagged ensemble:\")\n",
        "print(refit_model_map)\n",
        "predictor.leaderboard(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8a611c",
      "metadata": {
        "id": "ee8a611c"
      },
      "source": [
        "This adds the refit-full models to the leaderboard and we can opt to use any of them for prediction just like any other model. Note `pred_time_test` and `pred_time_val` list the time taken to produce predictions with each model (in seconds) on the test/validation data. Since the refit-full models were trained using all of the data, there is no internal validation score (`score_val`) available for them. You can also call `refit_full()` with non-bagged models to refit the same models to your full dataset (there won't be memory/latency gains in this case but test accuracy may improve).\n",
        "\n",
        "### Model distillation\n",
        "\n",
        "While computationally-favorable, single individual models will usually have lower accuracy than weighted/stacked/bagged ensembles. [Model Distillation](https://arxiv.org/abs/2006.14284) offers one way to retain the computational benefits of a single model, while enjoying some of the accuracy-boost that comes with ensembling. The idea is to train the individual model (which we can call the student) to mimic the predictions of the full stack ensemble (the teacher). Like `refit_full()`, the `distill()` function will produce additional models we can opt to use for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "13d8854f",
      "metadata": {
        "id": "13d8854f",
        "outputId": "f29ace0a-08ca-43b4-dd7d-405036e35000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Distilling with teacher='WeightedEnsemble_L2_FULL', teacher_preds=soft, augment_method=spunge ...\n",
            "SPUNGE: Augmenting training data with 4000 synthetic samples for distillation...\n",
            "Distilling with each of these student models: ['LightGBM_DSTL', 'CatBoost_DSTL', 'RandomForestMSE_DSTL', 'NeuralNetTorch_DSTL']\n",
            "Fitting 4 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_DSTL ... Training model for up to 30.00s of the 30.00s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.7 GB\n",
            "\tNote: model has different eval_metric than default.\n",
            "\t-0.1104\t = Validation score   (-mean_squared_error)\n",
            "\t0.45s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: CatBoost_DSTL ... Training model for up to 29.54s of the 29.54s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\tNote: model has different eval_metric than default.\n",
            "\t-0.1053\t = Validation score   (-mean_squared_error)\n",
            "\t1.74s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_DSTL ... Training model for up to 27.79s of the 27.79s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\tNote: model has different eval_metric than default.\n",
            "\t-0.1176\t = Validation score   (-mean_squared_error)\n",
            "\t1.24s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_DSTL ... Training model for up to 26.44s of the 26.44s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.7 GB\n",
            "\tNote: model has different eval_metric than default.\n",
            "\t-0.1362\t = Validation score   (-mean_squared_error)\n",
            "\t5.57s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Distilling with each of these student models: ['WeightedEnsemble_L2_DSTL']\n",
            "Fitting model: WeightedEnsemble_L2_DSTL ... Training model for up to 30.00s of the 20.85s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_DSTL': 0.6, 'LightGBM_DSTL': 0.15, 'RandomForestMSE_DSTL': 0.15, 'NeuralNetTorch_DSTL': 0.1}\n",
            "\tNote: model has different eval_metric than default.\n",
            "\t-0.1041\t = Validation score   (-mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Distilled model leaderboard:\n",
            "                      model  score_val         eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0             CatBoost_DSTL   0.761087  mean_squared_error       0.003549  1.742907                0.003549           1.742907            1       True          8\n",
            "1  WeightedEnsemble_L2_DSTL   0.751283  mean_squared_error       0.061603  9.037771                0.000421           0.028955            2       True         11\n",
            "2      RandomForestMSE_DSTL   0.744308  mean_squared_error       0.045210  1.244537                0.045210           1.244537            1       True          9\n",
            "3       NeuralNetTorch_DSTL   0.712067  mean_squared_error       0.009701  5.570217                0.009701           5.570217            1       True         10\n",
            "4             LightGBM_DSTL   0.699171  mean_squared_error       0.002723  0.451155                0.002723           0.451155            1       True          7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LightGBM_DSTL', 'CatBoost_DSTL', 'RandomForestMSE_DSTL', 'NeuralNetTorch_DSTL', 'WeightedEnsemble_L2_DSTL']\n",
            "predictions from LightGBM_DSTL: [' <=50K', ' <=50K', ' >50K', ' <=50K', ' <=50K']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          model  score_test  score_val         eval_metric  \\\n",
              "0                 CatBoost_DSTL    0.759856   0.761087  mean_squared_error   \n",
              "1          LightGBM_BAG_L1_FULL    0.750092        NaN   balanced_accuracy   \n",
              "2      WeightedEnsemble_L2_FULL    0.750092        NaN   balanced_accuracy   \n",
              "3      WeightedEnsemble_L2_DSTL    0.745092   0.751283  mean_squared_error   \n",
              "4               LightGBM_BAG_L1    0.743784   0.776399   balanced_accuracy   \n",
              "5           WeightedEnsemble_L2    0.743784   0.776399   balanced_accuracy   \n",
              "6        NeuralNetFastAI_BAG_L1    0.728689   0.725071   balanced_accuracy   \n",
              "7          RandomForestMSE_DSTL    0.721634   0.744308  mean_squared_error   \n",
              "8                 LightGBM_DSTL    0.718498   0.699171  mean_squared_error   \n",
              "9           NeuralNetTorch_DSTL    0.717051   0.712067  mean_squared_error   \n",
              "10  NeuralNetFastAI_BAG_L1_FULL    0.709449        NaN   balanced_accuracy   \n",
              "\n",
              "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
              "0         0.006691       0.003549   1.742907                 0.006691   \n",
              "1         0.017138            NaN   0.268760                 0.017138   \n",
              "2         0.018167            NaN   0.287227                 0.001029   \n",
              "3         0.150988       0.061603   9.037771                 0.001920   \n",
              "4         0.144379       0.064090   9.282016                 0.144379   \n",
              "5         0.145458       0.064651   9.300483                 0.001079   \n",
              "6         0.727401       0.054682  13.619211                 0.727401   \n",
              "7         0.094459       0.045210   1.244537                 0.094459   \n",
              "8         0.007737       0.002723   0.451155                 0.007737   \n",
              "9         0.040182       0.009701   5.570217                 0.040182   \n",
              "10        0.092718            NaN   0.284884                 0.092718   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                 0.003549           1.742907            1       True   \n",
              "1                      NaN           0.268760            1       True   \n",
              "2                      NaN           0.018467            2       True   \n",
              "3                 0.000421           0.028955            2       True   \n",
              "4                 0.064090           9.282016            1       True   \n",
              "5                 0.000561           0.018467            2       True   \n",
              "6                 0.054682          13.619211            1       True   \n",
              "7                 0.045210           1.244537            1       True   \n",
              "8                 0.002723           0.451155            1       True   \n",
              "9                 0.009701           5.570217            1       True   \n",
              "10                     NaN           0.284884            1       True   \n",
              "\n",
              "    fit_order  \n",
              "0           8  \n",
              "1           4  \n",
              "2           6  \n",
              "3          11  \n",
              "4           1  \n",
              "5           3  \n",
              "6           2  \n",
              "7           9  \n",
              "8           7  \n",
              "9          10  \n",
              "10          5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faf60f23-bb71-4b0a-b0c7-8a108d84ec77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CatBoost_DSTL</td>\n",
              "      <td>0.759856</td>\n",
              "      <td>0.761087</td>\n",
              "      <td>mean_squared_error</td>\n",
              "      <td>0.006691</td>\n",
              "      <td>0.003549</td>\n",
              "      <td>1.742907</td>\n",
              "      <td>0.006691</td>\n",
              "      <td>0.003549</td>\n",
              "      <td>1.742907</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBM_BAG_L1_FULL</td>\n",
              "      <td>0.750092</td>\n",
              "      <td>NaN</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.017138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.268760</td>\n",
              "      <td>0.017138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.268760</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WeightedEnsemble_L2_FULL</td>\n",
              "      <td>0.750092</td>\n",
              "      <td>NaN</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.018167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.287227</td>\n",
              "      <td>0.001029</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WeightedEnsemble_L2_DSTL</td>\n",
              "      <td>0.745092</td>\n",
              "      <td>0.751283</td>\n",
              "      <td>mean_squared_error</td>\n",
              "      <td>0.150988</td>\n",
              "      <td>0.061603</td>\n",
              "      <td>9.037771</td>\n",
              "      <td>0.001920</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.028955</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.144379</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>0.144379</td>\n",
              "      <td>0.064090</td>\n",
              "      <td>9.282016</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.743784</td>\n",
              "      <td>0.776399</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.145458</td>\n",
              "      <td>0.064651</td>\n",
              "      <td>9.300483</td>\n",
              "      <td>0.001079</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.728689</td>\n",
              "      <td>0.725071</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.727401</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>0.727401</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>13.619211</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForestMSE_DSTL</td>\n",
              "      <td>0.721634</td>\n",
              "      <td>0.744308</td>\n",
              "      <td>mean_squared_error</td>\n",
              "      <td>0.094459</td>\n",
              "      <td>0.045210</td>\n",
              "      <td>1.244537</td>\n",
              "      <td>0.094459</td>\n",
              "      <td>0.045210</td>\n",
              "      <td>1.244537</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LightGBM_DSTL</td>\n",
              "      <td>0.718498</td>\n",
              "      <td>0.699171</td>\n",
              "      <td>mean_squared_error</td>\n",
              "      <td>0.007737</td>\n",
              "      <td>0.002723</td>\n",
              "      <td>0.451155</td>\n",
              "      <td>0.007737</td>\n",
              "      <td>0.002723</td>\n",
              "      <td>0.451155</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NeuralNetTorch_DSTL</td>\n",
              "      <td>0.717051</td>\n",
              "      <td>0.712067</td>\n",
              "      <td>mean_squared_error</td>\n",
              "      <td>0.040182</td>\n",
              "      <td>0.009701</td>\n",
              "      <td>5.570217</td>\n",
              "      <td>0.040182</td>\n",
              "      <td>0.009701</td>\n",
              "      <td>5.570217</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
              "      <td>0.709449</td>\n",
              "      <td>NaN</td>\n",
              "      <td>balanced_accuracy</td>\n",
              "      <td>0.092718</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.284884</td>\n",
              "      <td>0.092718</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.284884</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faf60f23-bb71-4b0a-b0c7-8a108d84ec77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-faf60f23-bb71-4b0a-b0c7-8a108d84ec77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-faf60f23-bb71-4b0a-b0c7-8a108d84ec77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bc1b8125-693c-4f3e-a8eb-daf0f74114ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc1b8125-693c-4f3e-a8eb-daf0f74114ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bc1b8125-693c-4f3e-a8eb-daf0f74114ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"WeightedEnsemble_L2\",\n          \"CatBoost_DSTL\",\n          \"NeuralNetTorch_DSTL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01671690572275977,\n        \"min\": 0.7094486104151958,\n        \"max\": 0.7598562839484286,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7170511708998069,\n          0.7500924359540138,\n          0.7216341182872188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02885246829482435,\n        \"min\": 0.6991709435452034,\n        \"max\": 0.776398689516129,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7610869851296224,\n          0.7512830635609948,\n          0.6991709435452034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"balanced_accuracy\",\n          \"mean_squared_error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2058813028808338,\n        \"min\": 0.0066907405853271484,\n        \"max\": 0.7274010181427002,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.14545774459838867,\n          0.0066907405853271484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028055963299224423,\n        \"min\": 0.0027227401733398438,\n        \"max\": 0.0646512508392334,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.06160330772399902,\n          0.04521012306213379\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.884570269859293,\n        \"min\": 0.26875996589660645,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          9.300482749938965,\n          1.7429065704345703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21270623412848447,\n        \"min\": 0.0010290145874023438,\n        \"max\": 0.7274010181427002,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.0010788440704345703,\n          0.0066907405853271484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027160704263026383,\n        \"min\": 0.0004208087921142578,\n        \"max\": 0.06408977508544922,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.0004208087921142578,\n          0.04521012306213379\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.597972697868998,\n        \"min\": 0.018466711044311523,\n        \"max\": 13.619211196899414,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5.57021689414978,\n          0.26875996589660645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 11,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "student_models = predictor.distill(time_limit=30)  # specify much longer time limit in real applications\n",
        "print(student_models)\n",
        "preds_student = predictor.predict(test_data_nolabel, model=student_models[0])\n",
        "print(f\"predictions from {student_models[0]}:\", list(preds_student)[:5])\n",
        "predictor.leaderboard(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba4a36ab",
      "metadata": {
        "id": "ba4a36ab"
      },
      "source": [
        "### Faster presets or hyperparameters\n",
        "\n",
        "Instead of trying to speed up a cumbersome trained model at prediction time, if you know inference latency or memory will be an issue at the outset, then you can adjust the training process accordingly to ensure `fit()` does not produce unwieldy models.\n",
        "\n",
        "One option is to specify more lightweight `presets`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3bd5e5e4",
      "metadata": {
        "id": "3bd5e5e4",
        "outputId": "13d626b8-8de2-4869-ec51-7dc6a7f5d57a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251018_192127\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          4\n",
            "Memory Avail:       43.59 GB / 47.05 GB (92.7%)\n",
            "Disk Space Avail:   196.70 GB / 225.33 GB (87.3%)\n",
            "===================================================\n",
            "Presets specified: ['good_quality', 'optimize_for_deployment']\n",
            "Using hyperparameters preset: hyperparameters='light'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
            "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20251018_192127/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                      model  score_holdout  score_val eval_metric  pred_time_test pred_time_val  fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L1_FULL       0.866071   0.862613    accuracy        0.003729          None  0.607138                 0.003729                   None           0.607138            1       True          1\n",
            "1  WeightedEnsemble_L3_FULL       0.866071   0.862613    accuracy        0.004573          None  0.608938                 0.000843                   None           0.001800            3       True          3\n",
            "2  WeightedEnsemble_L2_FULL       0.866071   0.862613    accuracy        0.004652          None  0.609212                 0.000923                   None           0.002074            2       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t15s\t = DyStack   runtime |\t15s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 15s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251018_192127\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    44264.24 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.50 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.07s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 10.01s of the 15.02s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t0.859\t = Validation score   (accuracy)\n",
            "\t6.25s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 15.02s of the 4.37s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.859\t = Validation score   (accuracy)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4.37s of the 4.36s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t0.861\t = Validation score   (accuracy)\n",
            "\t7.77s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 15.02s of the -5.37s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
            "\t0.861\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 20.49s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1530.6 rows/s (125 batch size)\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\t0.26s\t = Training   runtime\n",
            "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\t0.24s\t = Training   runtime\n",
            "Updated best model to \"LightGBMXT_BAG_L2_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"LightGBMXT_BAG_L2_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 0.51s ... Best model: \"LightGBMXT_BAG_L2_FULL\"\n",
            "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (1000 rows).\n",
            "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
            "Deleting model LightGBMXT_BAG_L1. All files under /content/AutogluonModels/ag-20251018_192127/models/LightGBMXT_BAG_L1 will be removed.\n",
            "Deleting model WeightedEnsemble_L2. All files under /content/AutogluonModels/ag-20251018_192127/models/WeightedEnsemble_L2 will be removed.\n",
            "Deleting model LightGBMXT_BAG_L2. All files under /content/AutogluonModels/ag-20251018_192127/models/LightGBMXT_BAG_L2 will be removed.\n",
            "Deleting model WeightedEnsemble_L3. All files under /content/AutogluonModels/ag-20251018_192127/models/WeightedEnsemble_L3 will be removed.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251018_192127\")\n"
          ]
        }
      ],
      "source": [
        "presets = ['good_quality', 'optimize_for_deployment']\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, presets=presets, time_limit=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d97180",
      "metadata": {
        "id": "b8d97180"
      },
      "source": [
        "Another option is to specify more lightweight hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3e808d32",
      "metadata": {
        "id": "3e808d32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f164dc85-f4f2-447f-90de-12e0f9bab49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251018_192203\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          4\n",
            "Memory Avail:       43.47 GB / 47.05 GB (92.4%)\n",
            "Disk Space Avail:   196.70 GB / 225.33 GB (87.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
            "Using hyperparameters preset: hyperparameters='very_light'\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251018_192203\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    44516.36 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.50 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.07s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "}\n",
            "Fitting 7 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 29.93s of the 29.93s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.5 GB\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 29.58s of the 29.58s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.5 GB\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 29.18s of the 29.18s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.86\t = Validation score   (accuracy)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 27.62s of the 27.62s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.5 GB\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 26.88s of the 26.88s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.855\t = Validation score   (accuracy)\n",
            "\t0.16s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 26.71s of the 26.71s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.5 GB\n",
            "\t0.855\t = Validation score   (accuracy)\n",
            "\t2.2s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ... Training model for up to 24.49s of the 24.49s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.5 GB\n",
            "\t0.795\t = Validation score   (accuracy)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.93s of the 23.55s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost': 0.5, 'XGBoost': 0.5}\n",
            "\t0.865\t = Validation score   (accuracy)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.5s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 24566.2 rows/s (200 batch size)\n",
            "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (200 rows).\n",
            "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251018_192203\")\n"
          ]
        }
      ],
      "source": [
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, hyperparameters='very_light', time_limit=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d49c182b",
      "metadata": {
        "id": "d49c182b"
      },
      "source": [
        "Here you can set `hyperparameters` to either 'light', 'very_light', or 'toy' to obtain progressively smaller (but less accurate) models and predictors. Advanced users may instead try manually specifying particular models' hyperparameters in order to make them faster/smaller.\n",
        "\n",
        "Finally, you may also exclude specific unwieldy models from being trained at all. Below we exclude models that tend to be slower (K Nearest Neighbors, Neural Networks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ae2298e4",
      "metadata": {
        "id": "ae2298e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3c7958-de8d-41dc-ac5f-da3c63830c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251018_192210\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          4\n",
            "Memory Avail:       43.46 GB / 47.05 GB (92.4%)\n",
            "Disk Space Avail:   196.70 GB / 225.33 GB (87.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251018_192210\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    44635.68 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.50 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.07s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Excluded models: ['NN_TORCH'] (Specified by `excluded_model_types`)\n",
            "Fitting 10 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 29.93s of the 29.93s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.6 GB\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 29.61s of the 29.61s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.6 GB\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ... Training model for up to 29.22s of the 29.22s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ... Training model for up to 28.76s of the 28.76s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.835\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 28.29s of the 28.29s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.86\t = Validation score   (accuracy)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 26.74s of the 26.74s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.815\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 26.27s of the 26.27s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.82\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 25.81s of the 25.81s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.6 GB\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 25.09s of the 25.09s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0\n",
            "\t0.855\t = Validation score   (accuracy)\n",
            "\t0.16s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ... Training model for up to 24.93s of the 24.93s of remaining time.\n",
            "\tFitting with cpus=4, gpus=0, mem=0.0/43.6 GB\n",
            "\t0.795\t = Validation score   (accuracy)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.93s of the 23.99s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestGini': 0.429, 'CatBoost': 0.286, 'LightGBMXT': 0.143, 'ExtraTreesEntr': 0.143}\n",
            "\t0.875\t = Validation score   (accuracy)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.07s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2074.6 rows/s (200 batch size)\n",
            "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (200 rows).\n",
            "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251018_192210\")\n"
          ]
        }
      ],
      "source": [
        "excluded_model_types = ['KNN', 'NN_TORCH']\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, excluded_model_types=excluded_model_types, time_limit=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd7ac48",
      "metadata": {
        "id": "7cd7ac48"
      },
      "source": [
        "### (Advanced) Cache preprocessed data\n",
        "\n",
        "If you are repeatedly predicting on the same data you can cache the preprocessed version of the data and\n",
        "directly send the preprocessed data to `predictor.predict` for faster inference:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_preprocessed = predictor.transform_features(test_data)\n",
        "\n",
        "# The following call will be faster than a normal predict call because we are skipping the preprocessing stage.\n",
        "predictions = predictor.predict(test_data_preprocessed, transform_features=False)"
      ],
      "metadata": {
        "id": "9JmXoxphqTNd"
      },
      "id": "9JmXoxphqTNd",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4aa0c796",
      "metadata": {
        "id": "4aa0c796"
      },
      "source": [
        "```\n",
        "test_data_preprocessed = predictor.transform_features(test_data)\n",
        "\n",
        "# The following call will be faster than a normal predict call because we are skipping the preprocessing stage.\n",
        "predictions = predictor.predict(test_data_preprocessed, transform_features=False)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782040dc",
      "metadata": {
        "id": "782040dc"
      },
      "source": [
        "Note that this is only useful in situations where you are repeatedly predicting on the same data.\n",
        "If this significantly speeds up your use-case, consider whether your current approach makes sense\n",
        "or if a cache on the predictions is a better solution.\n",
        "\n",
        "### (Advanced) Disable preprocessing\n",
        "\n",
        "If you would rather do data preprocessing outside of TabularPredictor,\n",
        "you can disable TabularPredictor's preprocessing entirely via:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ca510b",
      "metadata": {
        "id": "15ca510b"
      },
      "source": [
        "```\n",
        "predictor.fit(..., feature_generator=None, feature_metadata=YOUR_CUSTOM_FEATURE_METADATA)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d32cbe6",
      "metadata": {
        "id": "6d32cbe6"
      },
      "source": [
        "Be warned that this removes ALL guardrails on data sanitization.\n",
        "It is very likely that you will run into errors doing this unless you are very familiar with AutoGluon.\n",
        "\n",
        "One instance where this can be helpful is if you have many problems\n",
        "that re-use the exact same data with the exact same features. If you had 30 tasks that re-use the same features,\n",
        "you could fit a `autogluon.features` feature generator once on the data, and then when you need to\n",
        "predict on the 30 tasks, preprocess the data only once and then send the preprocessed data to all 30 predictors.\n",
        "\n",
        "\n",
        "## If you encounter memory issues\n",
        "\n",
        "To reduce memory usage during training, you may try each of the following strategies individually or combinations of them (these may harm accuracy):\n",
        "\n",
        "- In `fit()`, set `excluded_model_types = ['KNN', 'XT' ,'RF']` (or some subset of these models).\n",
        "- Try different `presets` in `fit()`.\n",
        "- In `fit()`, set `hyperparameters = 'light'` or `hyperparameters = 'very_light'`.\n",
        "- Text fields in your table require substantial memory for N-gram featurization. To mitigate this in `fit()`, you can either: (1) add `'ignore_text'` to your `presets` list (to ignore text features), or (2) specify the argument:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d30ebcf6",
      "metadata": {
        "id": "d30ebcf6"
      },
      "source": [
        "```\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
        "feature_generator = AutoMLPipelineFeatureGenerator(vectorizer=CountVectorizer(min_df=30, ngram_range=(1, 3), max_features=MAX_NGRAM, dtype=np.uint8))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f1b86fb",
      "metadata": {
        "id": "6f1b86fb"
      },
      "source": [
        "for example using `MAX_NGRAM = 1000` (try various values under 10000 to reduce the number of N-gram features used to represent each text field)\n",
        "\n",
        "In addition to reducing memory usage, many of the above strategies can also be used to reduce training times.\n",
        "\n",
        "To reduce memory usage during inference:\n",
        "\n",
        "- If trying to produce predictions for a large test dataset, break the test data into smaller chunks as demonstrated in [FAQ](tabular-faq.ipynb).\n",
        "\n",
        "- If models have been previously persisted in memory but inference-speed is not a major concern, call `predictor.unpersist()`.\n",
        "\n",
        "- If models have been previously persisted in memory, bagging was used in `fit()`, and inference-speed is a concern: call `predictor.refit_full()` and use one of the refit-full models for prediction (ensure this is the only model persisted in memory).\n",
        "\n",
        "\n",
        "\n",
        "## If you encounter disk space issues\n",
        "\n",
        "To reduce disk usage, you may try each of the following strategies individually or combinations of them:\n",
        "\n",
        "- Make sure to delete all `predictor.path` folders from previous `fit()` runs! These can eat up your free space if you call `fit()` many times. If you didn't specify `path`, AutoGluon still automatically saved its models to a folder called: \"AutogluonModels/ag-[TIMESTAMP]\", where TIMESTAMP records when `fit()` was called, so make sure to also delete these folders if you run low on free space.\n",
        "\n",
        "- Call `predictor.save_space()` to delete auxiliary files produced during `fit()`.\n",
        "\n",
        "- Call `predictor.delete_models(models_to_keep='best', dry_run=False)` if you only intend to use this predictor for inference going forward (will delete files required for non-prediction-related functionality like `fit_summary`).\n",
        "\n",
        "- In `fit()`, you can add `'optimize_for_deployment'` to the `presets` list, which will automatically invoke the previous two strategies after training.\n",
        "\n",
        "- Most of the above strategies to reduce memory usage will also reduce disk usage (but may harm accuracy).\n",
        "\n",
        "\n",
        "## References\n",
        "\n",
        "The following paper describes how AutoGluon internally operates on tabular data:\n",
        "\n",
        "Erickson et al. [AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data](https://arxiv.org/abs/2003.06505). *Arxiv*, 2020.\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "If you are interested in deployment optimization, refer to the [Predicting Columns in a Table - Deployment Optimization](advanced/tabular-deployment.ipynb) tutorial."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "accelerator": "TPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bc2430645de4adb8655d48987b6284f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_344166432375424aadf062667c1d8a0b",
              "IPY_MODEL_817e6d6d62814965ba9b831fbc4ca5f2",
              "IPY_MODEL_dc2a107fea8149c7860ce477104721ed"
            ],
            "layout": "IPY_MODEL_b5c96e7c556d491c86bec0d846d5b36a"
          }
        },
        "344166432375424aadf062667c1d8a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e631b6c08efa41f1817dd6522349e151",
            "placeholder": "​",
            "style": "IPY_MODEL_496e6fd96f4e4a4dbb6cee425a245c8e",
            "value": "100%"
          }
        },
        "817e6d6d62814965ba9b831fbc4ca5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_541564df09a349feb13b40905b202a08",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baf74ab673ff4fd9a3b557340640d7e3",
            "value": 5
          }
        },
        "dc2a107fea8149c7860ce477104721ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c07432e8034d9496fb00ecd9a4c597",
            "placeholder": "​",
            "style": "IPY_MODEL_cccb5184107c4244a6b0b0a3edb929ba",
            "value": " 5/5 [00:03&lt;00:00,  1.43it/s]"
          }
        },
        "b5c96e7c556d491c86bec0d846d5b36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e631b6c08efa41f1817dd6522349e151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496e6fd96f4e4a4dbb6cee425a245c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "541564df09a349feb13b40905b202a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf74ab673ff4fd9a3b557340640d7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16c07432e8034d9496fb00ecd9a4c597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cccb5184107c4244a6b0b0a3edb929ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}