{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0fa7eb3d",
      "metadata": {
        "id": "0fa7eb3d"
      },
      "source": [
        "# How to use AutoGluon for Kaggle competitions\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb)\n",
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "This tutorial will teach you how to use AutoGluon to become a serious Kaggle competitor without writing lots of code.\n",
        "We first outline the general steps to use AutoGluon in Kaggle contests. Here, we assume the competition involves tabular data which are stored in one (or more) CSV files.\n",
        "\n",
        "1) Run Bash command: pip install kaggle\n",
        "\n",
        "2) Navigate to: https://www.kaggle.com/account and create an account (if necessary).\n",
        "Then , click on \"Create New API Token\" and move downloaded file to this location on your machine: `~/.kaggle/kaggle.json`. For troubleshooting, see [Kaggle API instructions](https://www.kaggle.com/docs/api).\n",
        "\n",
        "3) To download data programmatically: Execute this Bash command in your terminal:\n",
        "\n",
        "`kaggle competitions download -c [COMPETITION]`\n",
        "\n",
        "Here, [COMPETITION] should be replaced by the name of the competition you wish to enter.\n",
        "Alternatively, you can download data manually: Just navigate to website of the Kaggle competition you wish to enter, click \"Download All\", and accept the competition's terms.\n",
        "\n",
        "4) If the competition's training data is comprised of multiple CSV files, use [pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to properly merge/join them into a single data table where rows = training examples, columns = features.\n",
        "\n",
        "5) Run autogluon `fit()` on the resulting data table.\n",
        "\n",
        "6) Load the test dataset from competition (again making the necessary merges/joins to ensure it is in the exact same format as the training data table), and then call autogluon `predict()`.  Subsequently use [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to load the competition's `sample_submission.csv` file into a DataFrame, put the AutoGluon predictions in the right column of this DataFrame, and finally save it as a CSV file via [pandas.to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html). If the competition does not offer a sample submission file, you will need to create the submission file yourself by appropriately reformatting AutoGluon's test predictions.\n",
        "\n",
        "7) Submit your predictions via Bash command:\n",
        "\n",
        "`kaggle competitions submit -c [COMPETITION] -f [FILE] -m [\"MESSAGE\"]`\n",
        "\n",
        "Here, [COMPETITION] again is the competition's name, [FILE] is the name of the CSV file you created with your predictions, and [\"MESSAGE\"] is a string message you want to record with this submitted entry. Alternatively, you can  manually upload your file of predictions on the competition website.\n",
        "\n",
        "8) Finally, navigate to competition leaderboard website to see how well your submission performed!\n",
        "It may take time for your submission to appear.\n",
        "\n",
        "\n",
        "\n",
        "Below, we demonstrate how to do steps (4)-(6) in Python for a specific Kaggle competition: [ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection/).\n",
        "This means you'll need to run the above steps with `[COMPETITION]` replaced by `ieee-fraud-detection` in each command.  Here, we assume you've already completed steps (1)-(3) and the data CSV files are available on your computer. To begin step (4), we first load the competition's training data into Python:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Kaggle Key and Username as Secrets, Download Dataset and unzip it"
      ],
      "metadata": {
        "id": "8N_l8CmdFAqq"
      },
      "id": "8N_l8CmdFAqq"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "\n",
        "!unzip /content/ieee-fraud-detection.zip -d /content/ieee-fraud-detection"
      ],
      "metadata": {
        "id": "LFeaRb-qElMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c07ce3-f890-429c-eb8e-9df1be7a16de"
      },
      "id": "LFeaRb-qElMe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ieee-fraud-detection.zip to /content\n",
            "\r  0% 0.00/118M [00:00<?, ?B/s]\n",
            "\r100% 118M/118M [00:00<00:00, 2.90GB/s]\n",
            "Archive:  /content/ieee-fraud-detection.zip\n",
            "  inflating: /content/ieee-fraud-detection/sample_submission.csv  \n",
            "  inflating: /content/ieee-fraud-detection/test_identity.csv  \n",
            "  inflating: /content/ieee-fraud-detection/test_transaction.csv  \n",
            "  inflating: /content/ieee-fraud-detection/train_identity.csv  \n",
            "  inflating: /content/ieee-fraud-detection/train_transaction.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U pip\n",
        "!pip3 install -U setuptools wheel\n",
        "\n",
        "!pip3 install autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "C5wB9IDmFdqz",
        "outputId": "b9e71d8e-2181-43f3-fa51-0f9f983422f2"
      },
      "id": "C5wB9IDmFdqz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools\n",
            "\u001b[2K  Attempting uninstall: setuptools\n",
            "\u001b[2K    Found existing installation: setuptools 75.2.0\n",
            "\u001b[2K    Uninstalling setuptools-75.2.0:\n",
            "\u001b[2K      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [setuptools]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-80.9.0 wheel-0.45.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources"
                ]
              },
              "id": "8214e99a09e64c1b906fbfd4e060521f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.4.0 (from autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.core-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.4.0 (from autogluon)\n",
            "  Downloading autogluon.features-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.4.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.tabular-1.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting autogluon.multimodal==1.4.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.timeseries==1.4.0 (from autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.timeseries-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.5)\n",
            "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.32.4)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading boto3-1.40.52-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting autogluon.common==1.4.0 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.common-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyarrow<21.0.0,>=7.0.0 (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.5.2)\n",
            "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting ray<2.45,>=2.10.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (11.3.0)\n",
            "Collecting torch<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting lightning<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.10.1)\n",
            "Collecting fsspec<=2025.3 (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting torchvision<0.23.0,>=0.16.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.25.2)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting omegaconf<2.4.0,>=2.1.1 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.9.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.1.6)\n",
            "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (2.8.4)\n",
            "Collecting loguru (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting lightgbm<4.7,>=4.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting einx (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting xgboost<3.1,>=2.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (3.8.7)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (0.35.3)\n",
            "Collecting pytorch-lightning (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting orjson~=3.9 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading orjson-3.11.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (0.6.2)\n",
            "Collecting botocore<1.41.0,>=1.40.52 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading botocore-1.40.52-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.52->boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.52->boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.5.0)\n",
            "Collecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (1.17.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (25.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.8.12)\n",
            "Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (2.5.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (3.1.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading aiohttp-3.13.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.12.0)\n",
            "Collecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.15.0)\n",
            "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.4.0->autogluon) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.27.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (80.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.2.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.62.1)\n",
            "Collecting optuna (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (2025.9.18)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (14.1.0)\n",
            "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.1 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.41.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (3.20.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.1.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (6.32.1)\n",
            "Collecting aiosignal (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading colorful-0.5.7-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.4.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.75.1)\n",
            "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.23.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (7.3.1)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading virtualenv-20.35.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.10.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2025.10.4)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.19.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Collecting statsmodels>=0.13.2 (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.14.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[torch]->autogluon.tabular[all]==1.4.0->autogluon) (1.1.10)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (0.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.17.3)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (6.7.0)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "  Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (4.13.5)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.45.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.1.2)\n",
            "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.3.0)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (2.8)\n",
            "Collecting frozendict (from einx->autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.25.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.38.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.6.1)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting filelock (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = './ieee-fraud-detection/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory + 'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')"
      ],
      "metadata": {
        "id": "jUWdETk3E9xH"
      },
      "id": "jUWdETk3E9xH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1b046735",
      "metadata": {
        "id": "1b046735"
      },
      "source": [
        "Since the training data for this competition is comprised of multiple CSV files, we just first join them into a single large table (with rows = examples, columns = features) before applying AutoGluon:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "YyJ1HnafGHze"
      },
      "id": "YyJ1HnafGHze",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7de8c287",
      "metadata": {
        "id": "7de8c287"
      },
      "source": [
        "Note that a left-join on the `TransactionID` key happened to be most appropriate for this Kaggle competition, but for others involving multiple training data files, you will likely need to use a different join strategy (always consider this very carefully). Now that all our training data resides within a single table, we can apply AutoGluon. Below, we specify the `presets` argument to maximize AutoGluon's predictive accuracy which usually requires that you run `fit()` with longer time limits (3600s below should likely be increased in your run):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='best_quality', time_limit=300)\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jScdB2CqGR8v",
        "outputId": "3f3bebf2-6231-4db5-b79f-779b3200d4c5"
      },
      "id": "jScdB2CqGR8v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=9062)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F8/model.pkl\n",
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./ieee-fraud-detection/AutoGluonModels/\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          4\n",
            "GPU Count:          0\n",
            "Memory Avail:       25.91 GB / 47.05 GB (55.1%)\n",
            "Disk Space Avail:   193.42 GB / 225.33 GB (85.8%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': True, 'num_bag_sets': 1}\n",
            "Full kwargs:\n",
            "{'_experimental_dynamic_hyperparameters': False,\n",
            " '_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': True,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': 1,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_model_failure': False,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\n",
            "\t\tContext path: \"/content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t0.9624\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t237.86s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t13.36s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t1308.0\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 41.52s of the 41.31s of remaining time.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 39.20% memory usage per fold, 78.41%/80.00% total).\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=39.20%)\n",
            "\u001b[36m(_ray_fit pid=9063)\u001b[0m \tRan out of time, early stopping on iteration 625. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=9063)\u001b[0m \t[625]\tvalid_set's binary_logloss: 0.051405\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=9572)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9572)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=9572)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.121229\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=9571)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9572)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F2/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=9742)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9742)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9742)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.120537\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9571)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F1/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=9753)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9742)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F3/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=9918)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9918)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9918)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.12164\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9918)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F5/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=9983)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=10101)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=10101)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=10101)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.120987\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9983)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F6/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=10106)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=10101)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F7/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t0.9479\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t47.2s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t0.63s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t1752.8\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -11.48s of remaining time.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 4\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Beginning AutoGluon training ... Time limit = 75s\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m AutoGluon will save models to \"/content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Train Data Rows:    524924\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Train Data Columns: 433\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Label Column:       isFraud\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_ray_fit pid=10106)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=10106)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.120462\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tAvailable Memory:                    26629.05 MB\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tTrain Data (Original)  Memory Usage: 2231.12 MB (8.4% of available memory)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tWarning: Data size prior to feature transformation consumes 8.4% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Ensemble size: 3\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m [0.         0.         0.66666667 0.33333333]\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t0.67s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.667, 'LightGBM_BAG_L2': 0.333}\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t0.9624\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t8.64s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t0.09s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m \t1291.6\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m AutoGluon training complete, total runtime = 925.03s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1291.6 rows/s (65616 batch size)\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.4.0\"\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/metadata.json\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t3.4s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t3.2s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t0.3s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t1.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t3.2s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t3 duplicate columns removed: ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t3.3s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t\t430 features in original data used to generate 430 features in processed data.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tUnused Original Features (Count: 3): ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('float', []) : 3 | ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('float64', 'float') : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('float', [])  : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('float64', 'float')     : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t21.5s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t430 features in original data used to generate 430 features in processed data.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tTrain Data (Processed) Memory Usage: 1614.47 MB (6.2% of available memory)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Data preprocessing and feature engineering runtime = 23.96s ...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}, {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 34.02s of the 51.02s of remaining time.\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\u001b[36m(_dystack pid=3605)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 4\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 36.14% memory usage per fold, 72.28%/80.00% total).\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=36.14%)\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=10662)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=10663)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=10663)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.14124\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=10663)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=10663)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F2/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=10832)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=10832)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=10832)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.141873\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=10662)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F1/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=10892)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=10832)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F3/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=11015)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=11015)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=11015)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.141632\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=10892)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F4/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=11016)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=11015)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F5/model.pkl\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=11191)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=11243)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=11243)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.141561\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=11243)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F8/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.12/dist-packages/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "\u001b[33m(raylet)\u001b[0m   import pkg_resources\n",
            "\u001b[36m(_ray_fit pid=11243)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.8002\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t46.36s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.67s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t97741.0\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForestGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 51.04s of the -12.93s of remaining time.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Ensemble size: 1\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m [1.]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.4s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.8002\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.05s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t96963.4\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBMXT_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 51.04s of the -13.29s of remaining time.\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 4\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Ensemble size: 1\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m [1.]\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.39s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.8002\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.05s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m \t96945.0\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m AutoGluon training complete, total runtime = 97.46s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 96963.4 rows/s (65616 batch size)\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.4.0\"\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/metadata.json\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\u001b[36m(_dystack pid=10281)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L1       0.832859   0.800213     roc_auc        0.681529       0.671325  46.356032                 0.681529                0.671325          46.356032            1       True          1\n",
            "1  WeightedEnsemble_L3       0.832859   0.800213     roc_auc        0.682845       0.715421  46.401452                 0.001316                0.044096           0.045419            3       True          3\n",
            "2  WeightedEnsemble_L2       0.832859   0.800213     roc_auc        0.683307       0.714395  46.403209                 0.001778                0.043069           0.047177            2       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t157s\t = DyStack   runtime |\t143s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 143s\n",
            "AutoGluon will save models to \"/content/ieee-fraud-detection/AutoGluonModels\"\n",
            "Train Data Rows:    590540\n",
            "Train Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    34866.58 MB\n",
            "\tTrain Data (Original)  Memory Usage: 2531.61 MB (7.3% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 7.3% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t2.0s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.3s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.3s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.1s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.0s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t2.3s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t4 duplicate columns removed: ['V28', 'V154', 'V155', 'V156']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t2.7s = Fit runtime\n",
            "\t\t\t429 features in original data used to generate 429 features in processed data.\n",
            "\tUnused Original Features (Count: 4): ['V28', 'V154', 'V155', 'V156']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 4 | ['V28', 'V154', 'V155', 'V156']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t14.9s = Fit runtime\n",
            "\t429 features in original data used to generate 429 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1811.77 MB (5.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 16.7s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}, {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "}\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/utils/data/y.pkl\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 84.26s of the 126.38s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 4\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 36.50% memory usage per fold, 73.00%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=36.50%)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\t0.8862\t = Validation score   (roc_auc)\n",
            "\t71.61s\t = Training   runtime\n",
            "\t1.46s\t = Validation runtime\n",
            "\t50602.4\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 6.68s of the 48.79s of remaining time.\n",
            "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 4\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 36.52% memory usage per fold, 73.03%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=36.52%)\n",
            "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 126.43s of the 40.45s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "\t0.5s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.8862\t = Validation score   (roc_auc)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "\t50193.9\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 40.23s of the 39.94s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 38.74% memory usage per fold, 77.47%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=38.74%)\n",
            "2025-10-15 00:54:26,463\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\t0.8489\t = Validation score   (roc_auc)\n",
            "\t49.65s\t = Training   runtime\n",
            "\t0.72s\t = Validation runtime\n",
            "\t33827.8\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 126.43s of the -15.22s of remaining time.\n",
            "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 4\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1. 0.]\n",
            "\t0.52s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.8862\t = Validation score   (roc_auc)\n",
            "\t4.48s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "\t50215.4\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 176.24s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 50193.9 rows/s (73818 batch size)\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/predictor.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/version.txt with contents \"1.4.0\"\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/ieee-fraud-detection/AutoGluonModels\")\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L1   0.886165     roc_auc       1.458783   71.610626                1.458783          71.610626            1       True          1\n",
            "1  WeightedEnsemble_L3   0.886165     roc_auc       1.548738   76.093275                0.089954           4.482648            3       True          4\n",
            "2  WeightedEnsemble_L2   0.886165     roc_auc       1.553780   71.711336                0.094997           0.100709            2       True          2\n",
            "3    LightGBMXT_BAG_L2   0.848925     roc_auc       2.182171  121.263384                0.723387          49.652758            2       True          3\n",
            "Number of models trained: 4\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/autogluon/core/utils/plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "010f5fef",
      "metadata": {
        "id": "010f5fef"
      },
      "source": [
        "Now, we use the trained AutoGluon Predictor to make predictions on the competition's test data. It is imperative that multiple test data files are joined together in the exact same manner as the training data. Because this competition is evaluated based on the AUC (Area under the ROC curve) metric, we ask AutoGluon for predicted class-probabilities rather than class predictions. In general, when to use `predict` vs `predict_proba` will depend on the particular competition."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_identity = pd.read_csv(directory+'test_identity.csv')\n",
        "test_transaction = pd.read_csv(directory+'test_transaction.csv')\n",
        "test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n",
        "\n",
        "# Reindex test_data to match the columns of train_data, filling missing columns with NaN\n",
        "test_data = test_data.reindex(columns=train_data.columns, fill_value=np.nan)\n",
        "\n",
        "y_predproba = predictor.predict_proba(test_data)\n",
        "y_predproba.head(5)  # some example predicted fraud-probabilities"
      ],
      "metadata": {
        "id": "cpizg9H1GlkN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "2f72a592-3ccd-45fb-c8f6-cdd7ae9cce61"
      },
      "id": "cpizg9H1GlkN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1\n",
              "0  0.989750  0.010250\n",
              "1  0.982773  0.017227\n",
              "2  0.983711  0.016289\n",
              "3  0.991767  0.008233\n",
              "4  0.987814  0.012186"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-015337d4-2dda-4629-a1c1-425ad90c9615\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.989750</td>\n",
              "      <td>0.010250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.982773</td>\n",
              "      <td>0.017227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.983711</td>\n",
              "      <td>0.016289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.991767</td>\n",
              "      <td>0.008233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.987814</td>\n",
              "      <td>0.012186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-015337d4-2dda-4629-a1c1-425ad90c9615')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-015337d4-2dda-4629-a1c1-425ad90c9615 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-015337d4-2dda-4629-a1c1-425ad90c9615');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-44695387-601d-416e-9a4b-93dda962badd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44695387-601d-416e-9a4b-93dda962badd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-44695387-601d-416e-9a4b-93dda962badd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_predproba"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c39f1d0f",
        "outputId": "7fcbc80e-b1e7-46ec-c30f-0db40a9d3c49"
      },
      "source": [
        "print(\"Columns in train_data:\")\n",
        "print(train_data.columns)\n",
        "\n",
        "print(\"\\nColumns in test_data after reindexing:\")\n",
        "print(test_data.columns)"
      ],
      "id": "c39f1d0f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in train_data:\n",
            "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
            "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=434)\n",
            "\n",
            "Columns in test_data after reindexing:\n",
            "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
            "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=434)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd379db",
      "metadata": {
        "id": "2cd379db"
      },
      "source": [
        "When submitting predicted probabilities for classification competitions, it is imperative these correspond to the same class expected by Kaggle. For binary classification tasks, you can see which class AutoGluon's predicted probabilities correspond to via:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class"
      ],
      "metadata": {
        "id": "8luFUUu5Gq72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154b6cdb-67fb-47f6-c8f4-a24afc190a43"
      },
      "id": "8luFUUu5Gq72",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb03739b",
      "metadata": {
        "id": "bb03739b"
      },
      "source": [
        "For multiclass classification tasks, you can see which classes AutoGluon's predicted probabilities correspond to via:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels  # classes in this list correspond to columns of predict_proba() output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-jck7eDS9xN",
        "outputId": "3895641f-687f-4922-f255-54a1f9125523"
      },
      "id": "2-jck7eDS9xN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb84c3e",
      "metadata": {
        "id": "8cb84c3e"
      },
      "source": [
        "Now, let's get prediction probabilities for the entire test data, while only getting the positive class predictions by specifying:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcYkKbDxS_p5",
        "outputId": "4bd168dc-aebe-4f1d-ab1b-396b782fd382"
      },
      "id": "dcYkKbDxS_p5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f26a317",
      "metadata": {
        "id": "9f26a317"
      },
      "source": [
        "Now that we have made a prediction for each row in the test dataset, we can submit these predictions to Kaggle. Most Kaggle competitions provide a sample submission file, in which you can simply overwrite the sample predictions with your own as we do below:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "PpDEYO6pTBkt"
      },
      "id": "PpDEYO6pTBkt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2fd99892",
      "metadata": {
        "id": "2fd99892"
      },
      "source": [
        "We have now completed steps (4)-(6) from the top of this tutorial. To submit your predictions to Kaggle, you can run the following command in your terminal (from the appropriate directory):\n",
        "\n",
        "`kaggle competitions submit -c ieee-fraud-detection -f sample_submission.csv -m \"my first submission\"`\n",
        "\n",
        "You can now play with different `fit()` arguments and feature-engineering techniques to try and maximize the rank of your submissions in the Kaggle Leaderboard!\n",
        "\n",
        "\n",
        "**Tips to maximize predictive performance:**\n",
        "\n",
        "   - Be sure to specify the appropriate evaluation metric if one is specified on the competition website! If you are unsure which metric is best, then simply do not specify this argument when invoking `fit()`; AutoGluon should still produce high-quality models by automatically inferring which metric to use.\n",
        "\n",
        "   - If the training examples are time-based and the competition test examples come from future data, we recommend you reserve the most recently-collected training examples as a separate validation dataset passed to `fit()`. Otherwise, you do not need to specify a validation set yourself and AutoGluon will automatically partition the competition training data into its own training/validation sets.\n",
        "\n",
        "   - Beyond simply specifying `presets = 'best_quality'`, you may play with more advanced `fit()` arguments such as: `num_bag_folds`, `num_stack_levels`, `num_bag_sets`, `hyperparameter_tune_kwargs`, `hyperparameters`, `refit_full`. However we recommend spending most of your time on feature-engineering and just specify `presets = 'best_quality'` inside the call to `fit()`.\n",
        "\n",
        "\n",
        "**Troubleshooting:**\n",
        "\n",
        "- Check that you have the right user-permissions on your computer to access the data files downloaded from Kaggle.\n",
        "\n",
        "- For issues downloading Kaggle data or submitting predictions, check your Kaggle account setup and the [Kaggle FAQ](https://www.kaggle.com/general/14438)."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}